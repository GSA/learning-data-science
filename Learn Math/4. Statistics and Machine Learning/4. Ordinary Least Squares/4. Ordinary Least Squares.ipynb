{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import linear_rainbow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, t\n",
    "from scipy.stats.stats import pearsonr\n",
    "import sys\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import random\n",
    "import seaborn as sns\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares\n",
    "In statistics, **ordinary least squares (OLS)** is a type of linear least squares method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function.\n",
    "\n",
    "Geometrically, this is seen as the sum of the squared distances, parallel to the axis of the dependent variable, between each data point in the set and the corresponding point on the regression surface – the smaller the differences, the better the model fits the data. The resulting estimator can be expressed by a simple formula, especially in the case of a simple linear regression, in which there is a single regressor on the right side of the regression equation.\n",
    "\n",
    "With the [Gauss–Markov theorem](https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem), a linear regression model in which the errors have expectation zero, are uncorrelated and have equal variances, the best linear unbiased estimator (BLUE) of the coefficients is given by the ordinary least squares (OLS) estimator, provided it exists. In other words, the OLS estimator is **consistent** when the regressors are exogenous, and **optimal** in the class of linear unbiased estimators when the errors are homoscedastic and serially uncorrelated. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances. Under the additional assumption that the errors are normally distributed, OLS is the maximum likelihood estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample = 200\n",
    "x = np.linspace(0, 10, nsample)\n",
    "X = np.column_stack((x, x**2))\n",
    "beta = np.array([1, 0.1, 10])\n",
    "e = np.random.normal(size=nsample)\n",
    "#data needs to have an intercept added\n",
    "X = sm.add_constant(X)\n",
    "y = np.dot(X, beta) + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the system using matrix notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created an [overdetermined system](https://en.wikipedia.org/wiki/Overdetermined_system) where there are more equations (i.e. rows) than unknowns (i.e. independent variables):\n",
    "\n",
    "$$\\sum_{j=1}^{p} X_{ij}\\beta_j = y_i,\\ (i=1, 2, \\dots, n)$$\n",
    "\n",
    "There are $n$ linear equations in $p$ unknown coefficients, $\\beta_1,\\beta_2,…,\\beta_p$, with $n > p$. (Note: for a linear model as above, not all of $\\mathbf X$ contains information on the data points. The first column is populated with ones, $X_{i1} = 1$, only the other columns contain actual data, so here $p = number of regressors + 1$.) This can be written in matrix form as:\n",
    "\n",
    "$$X\\beta=y$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\mathbf {X}=\\begin{bmatrix}\n",
    "X_{11} & X_{12} & \\cdots & X_{1p} \\\\\n",
    "X_{21} & X_{22} & \\cdots & X_{2p} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "X_{n1} & X_{n2} & \\cdots & X_{np}\n",
    "\\end{bmatrix} ,\n",
    "\\qquad \\boldsymbol \\beta = \\begin{bmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix} ,\n",
    "\\qquad \\mathbf y = \\begin{bmatrix}\n",
    "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Such a system usually has no exact solution, so the goal is instead to find the coefficients **$\\beta$** which fit the equations \"best\", in the sense of solving the quadratic minimization problem:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{arg\\,min}}\\,S(\\boldsymbol{\\beta})\n",
    "$$\n",
    "\n",
    "where the objective function $S$ is given by:\n",
    "\n",
    "$$\n",
    "S(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\bigl| y_i - \\sum_{j=1}^p X_{ij}\\beta_j\\bigr|^2 = \\bigl\\|\\mathbf y - \\mathbf X \\boldsymbol \\beta \\bigr\\|^2\n",
    "$$\n",
    "\n",
    "The justification for choosing this criterion depends on several assumptions, which derive from the [Gauss–Markov theorem](https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem) (more on those assumptions later).\n",
    "\n",
    "When the assumptions are met, this minimization problem has a unique solution, provided that the $p$ columns of the matrix $\\mathbf X$ are **linearly independent**, given by solving the normal equations:\n",
    "\n",
    "$$(\\mathbf X^{\\rm T} \\mathbf X )\\hat{\\boldsymbol{\\beta}}= \\mathbf X^{\\rm T} \\mathbf y.$$\n",
    "\n",
    "The matrix $\\mathbf {X} ^{\\rm {T}}\\mathbf {X}$ is known as the [Gramian matrix](https://en.wikipedia.org/wiki/Gramian_matrix) of $ \\mathbf {X} $ and possesses several nice properties such as being a [positive semi-definite matrix](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix#Negative-definite,_semidefinite_and_indefinite_matrices). The matrix $\\mathbf {X} ^{\\rm {T}}\\mathbf {y} $ is known as the [moment matrix](https://en.wikipedia.org/wiki/Moment_matrix) of regressand by regressors. Finally, $ {\\hat {\\boldsymbol {\\beta }}}$ is the coefficient vector of the least-squares hyperplane, expressed as:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}= (\\mathbf X^{\\rm T} \\mathbf X )^{-1} \\mathbf X^{\\rm T} \\mathbf y\n",
    "$$\n",
    "\n",
    "We can use numpy to calculate $\\hat{\\boldsymbol{\\beta}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89972015, 0.19429952, 9.9890047 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T = np.transpose(X)\n",
    "B_hat = np.dot(np.dot(np.linalg.inv(np.dot(X_T, X)), X_T), y)\n",
    "B_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used numpy to calculate $ \\hat{\\boldsymbol{\\beta}}= (\\mathbf X^{\\rm T} \\mathbf X )^{-1} \\mathbf X^{\\rm T} \\mathbf y $. The returned array contains the coefficients for our constant, $X_1$, and $X_2$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "#### Calculating the fitted values\n",
    "\n",
    "After we have estimated $\\beta$, the fitted values (or predicted values) from the regression will be:\n",
    "\n",
    "$$\n",
    "\\hat{y} = X\\hat\\beta = Py\n",
    "$$\n",
    "\n",
    "where $P = X(X^{T}X)^{−1}X^T$ is the projection matrix onto the space $V$ spanned by the columns of $X$. This matrix $P$ is also sometimes called the hat matrix because it \"puts a hat\" onto the variable $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89972015, 0.93470807, 1.02014423, 1.15602864, 1.34236129,\n",
       "       1.57914219, 1.86637133, 2.20404871, 2.59217434, 3.03074822])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.dot(np.dot(np.dot(X, np.linalg.inv(np.dot(X_T, X))), X_T), y)\n",
    "P[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error and Goodness of Fit\n",
    "Suppose $b$ is a \"candidate\" value for the parameter vector $\\beta$. The quantity $y_i − x_{i}^{T}b$, called the residual for the i-th observation, measures the vertical distance between the data point $(x_i, y_i)$ and the hyperplane $y = x^{T}b$, and thus assesses the degree of fit between the actual data and the model. The **sum of squared residuals (SSR)** (also called the error sum of squares (ESS) or residual sum of squares (RSS)) is a measure of the overall model fit:\n",
    "\n",
    "$$\n",
    "S(b) = \\sum_{i=1}^n (y_i - x_i ^\\mathrm{T} b)^2 = (y-Xb)^\\mathrm{T}(y-Xb)\n",
    "$$\n",
    "\n",
    "The value of $b$ which minimizes this sum is called the OLS estimator for $\\beta$, which is what we calculated above. Now, let's calculate the SSR by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219.71901589411047\n"
     ]
    }
   ],
   "source": [
    "ssr = np.dot(np.transpose(y - np.dot(X, B_hat)), y - np.dot(X, B_hat))\n",
    "print(ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another matrix, closely related to $P$ above, is the annihilator matrix $M = I_n − P$ (note that $I_n$ is referring to an [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix)). This is a projection matrix onto the space orthogonal to $V$. Both matrices $P$ and $M$ are symmetric and idempotent and relate to the data matrix $X$ via identities $1=PX = X$ and $MX=0$.\n",
    "\n",
    "Matrix $M$ creates the residuals from the regression:\n",
    "\n",
    "$$\n",
    "\\hat\\varepsilon = y - \\hat y = y - X\\hat\\beta = My = M(X\\beta+\\varepsilon) = (MX)\\beta + M\\varepsilon = M\\varepsilon\n",
    "$$\n",
    "\n",
    "Using these residuals we can estimate the value of $\\sigma^2$, called the [reduced chi-squared](https://en.wikipedia.org/wiki/Reduced_chi-squared_statistic):\n",
    "\n",
    "$$\n",
    "s^2 = \\frac{\\hat\\varepsilon ^\\mathrm{T} \\hat\\varepsilon}{n-p} = \\frac{(My)^\\mathrm{T} My}{n-p} = \\frac{y^\\mathrm{T} M^\\mathrm{T}My}{n-p}= \\frac{y ^\\mathrm{T} My}{n-p} = \\frac{S(\\hat\\beta)}{n-p},\\qquad\n",
    "    \\hat\\sigma^2 = \\frac{n-p}{n}\\;s^2\n",
    "$$\n",
    "\n",
    "The numerator, $n−p$, is the [statistical degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)). The first quantity, $s^2$, is the OLS estimate for $\\sigma^2$, whereas the second, $\\hat\\sigma^2$, is the MLE estimate for $\\sigma^2$. The two estimators are quite similar in large samples; the first estimator is always [unbiased](https://en.wikipedia.org/wiki/Bias_of_an_estimator), while the second estimator is biased but has a smaller [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error). In practice $s^2$ is used more often, since it is more convenient for the hypothesis testing. The square root of $s^2$ is called the regression standard error, standard error of the regression, or standard error of the equation. The value of $s$ provides the absolute measure in the units of the dependent variables of the typical distance that the data points fall from the regression line. Below, we'll caluclate $s$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0560894629610236\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "dof = n - p\n",
    "eps_hat = y - P\n",
    "eps_hat_T = np.transpose(eps_hat)\n",
    "s_2 = np.dot(eps_hat_T, eps_hat) / dof\n",
    "#regression standard error\n",
    "s = np.sqrt(s_2)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to assess the goodness-of-fit of the OLS regression by comparing how much the initial variation in the sample can be reduced by regressing onto $X$. The coefficient of determination $R^2$ is defined as a ratio of \"explained\" variance to the \"total\" variance of the dependent variable $y$:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\sum(\\hat y_i-\\overline{y})^2}{\\sum(y_i-\\overline{y})^2} = \\frac{y ^\\mathrm{T} P ^\\mathrm{T} LPy}{y ^\\mathrm{T} Ly} = 1 - \\frac{y ^\\mathrm{T} My}{y ^\\mathrm{T} Ly} = 1 - \\frac{\\rm SSR}{\\rm TSS}\n",
    "$$\n",
    "\n",
    "where TSS is the total sum of squares for the dependent variable, $L = I_n − 11^T/n$ ($1$ is an $n×1$ vector of ones) and L is a \"centering matrix\" which is equivalent to regression on a constant; it simply subtracts the mean from a variable. In order for $R^2$ to be meaningful, the matrix $X$ of data on regressors must contain a column vector of ones to represent the constant whose coefficient is the regression intercept. In that case, $R^2$ will always be a number between 0 and 1, with values close to 1 indicating a good degree of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17993561.903605234 17993781.62262119 0.9999877891695829\n"
     ]
    }
   ],
   "source": [
    "y_bar = np.mean(y)\n",
    "num = np.sum(np.square(P - y_bar))\n",
    "denom = np.sum(np.square(y - y_bar))\n",
    "r_2 = num / denom\n",
    "print(num, denom, r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient standard errors\n",
    "The variance-covariance matrix (or simply covariance matrix) of $\\hat {\\beta }$ is equal to:\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}[\\, \\hat\\beta \\mid X \\,] = \\sigma^2(X ^T X)^{-1} = \\sigma^2 Q\n",
    "$$\n",
    "\n",
    "Once we calculate that, the standard error of each coefficient ${\\hat {\\beta }}_{j}$ is equal to square root of the j-th diagonal element of this matrix. The estimate of this standard error is obtained by replacing the unknown quantity $\\sigma^2$ with its estimate $s^2$. Let's do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlessmcallister/.local/share/virtualenvs/learning-data-science-Oygx0A85/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22180862, 0.10248138, 0.00991963])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.linalg.inv(np.dot(np.transpose(X), X))\n",
    "#RuntimeWarning will occur due to negative off-diagonal values\n",
    "covar = np.sqrt(np.dot(s_2, Q))\n",
    "std_errs = np.diagonal(covar)\n",
    "std_errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These standard errors estimates of the standard deviations of each coefficient, i.e. the amount each coefficient varies across observsations. It can be thought of as a measure of the precision with which the regression coefficient is measured. \n",
    "\n",
    "If a coefficient is large compared to its standard error, then it is probably different from 0. How large is too large? The $t$ statistic, which is the coefficient divided by its standard error, can be compared to [Student's t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) to determine a $p$ value, which is the number that you really need to be looking at. \n",
    "\n",
    "The Student's t distribution describes how the mean of a sample with a certain number of observations (your $n$) is expected to behave. If 95% of the t distribution is closer to the mean than the t-value on the coefficient you are looking at, then you have a P value of 5%. This is also reffered to a significance level of 5%. The p-value is the probability of seeing a result as extreme as the one you are getting (a t value as large as yours) in a collection of random data in which the variable had no effect.\n",
    "\n",
    "Below, we'll calculate the t-statisics and p-values for our coeffecients given those standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4.05629023,    1.89594953, 1006.99414871])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = B_hat / std_errs\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stderr:   0.222 t-statistic =  4.056 pvalue = 0.0001\n",
      "stderr:   0.102 t-statistic =  1.896 pvalue = 0.0594\n",
      "stderr:   0.010 t-statistic = 1006.994 pvalue = 0.0000\n"
     ]
    }
   ],
   "source": [
    "for err, t_stat in zip(std_errs, ts):\n",
    "    pval = t.sf(np.abs(t_stat), n-1)*2  # two-sided p-value\n",
    "    print('stderr:  %6.3f t-statistic = %6.3f pvalue = %6.4f' % (err, t_stat, pval))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calucalte confidence intervals for these standard errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997201520803788 0.22180862328896475 4.056290232270428\n",
      "0.19429952228927938 0.10248137902386163 1.8959495289777368\n",
      "9.98900469615945 0.009919625361275723 1006.9941487059149\n"
     ]
    }
   ],
   "source": [
    "for coef, err, t_stat in zip(B_hat, std_errs, ts):\n",
    "    print(coef, err, t_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stderr:   0.222 t-statistic =  4.056 pvalue = 0.0001 lower_ci = 0.4623 upper_ci = 1.3371\n",
      "stderr:   0.102 t-statistic =  1.896 pvalue = 0.0594 lower_ci = -0.0078 upper_ci = 0.3964\n",
      "stderr:   0.010 t-statistic = 1006.994 pvalue = 0.0000 lower_ci = 9.9694 upper_ci = 10.0086\n"
     ]
    }
   ],
   "source": [
    "confidence = .95 #alpha = .05\n",
    "for coef, err, t_stat in zip(B_hat, std_errs, ts):\n",
    "    pval = t.sf(np.abs(t_stat), n-1)*2  # two-sided p-value\n",
    "    h = err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = coef - h\n",
    "    end = coef + h\n",
    "    print('stderr:  %6.3f t-statistic = %6.3f pvalue = %6.4f lower_ci = %6.4f upper_ci = %6.4f' % (err, \n",
    "                                                                                                   t_stat, \n",
    "                                                                                                   pval,\n",
    "                                                                                                   start,\n",
    "                                                                                                   end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS with Statsmodels\n",
    "Now that we've calculated the OLS model by hand, let's use statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 8.067e+06\n",
      "Date:                Fri, 19 Apr 2019   Prob (F-statistic):               0.00\n",
      "Time:                        07:46:29   Log-Likelihood:                -293.19\n",
      "No. Observations:                 200   AIC:                             592.4\n",
      "Df Residuals:                     197   BIC:                             602.3\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8997      0.222      4.056      0.000       0.462       1.337\n",
      "x1             0.1943      0.102      1.896      0.059      -0.008       0.396\n",
      "x2             9.9890      0.010   1006.994      0.000       9.969      10.009\n",
      "==============================================================================\n",
      "Omnibus:                        0.456   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.796   Jarque-Bera (JB):                0.514\n",
      "Skew:                          -0.112   Prob(JB):                        0.774\n",
      "Kurtosis:                       2.894   Cond. No.                         145.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89972015 0.19429952 9.9890047 ]\n",
      "[0.89972015 0.19429952 9.9890047 ]\n"
     ]
    }
   ],
   "source": [
    "print(results.params)\n",
    "print(B_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22180862 0.10248138 0.00991963]\n",
      "[0.22180862 0.10248138 0.00991963]\n"
     ]
    }
   ],
   "source": [
    "print(results.bse)\n",
    "print(std_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219.7190158941119\n",
      "219.71901589411047\n"
     ]
    }
   ],
   "source": [
    "print(results.ssr)\n",
    "print(ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our calculations came out the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Assumptions\n",
    "In order for OLS estimates to be valid, we need to make at least 6 assumptions:\n",
    "\n",
    "1. OLS model is linear in its parameters.\n",
    "2. Error term has 0 population mean\n",
    "3. Error term is not correlated with Xs\n",
    "4. No serial correlation (really only an issue with time series data)\n",
    "5. No heteroskedasticity \n",
    "6. No perfect multicolinearity\n",
    "\n",
    "Sometimes a 7th optional assumption is added:\n",
    "\n",
    "7. Error term is normally distributed\n",
    "\n",
    "\n",
    "Violations of these assumptions can result in things like incorrect signs for your coefficient estimates or unreliable variances for your OLS estimates, leading to confidence intervals that are too wide or too narrow.\n",
    "\n",
    "That being said, we'll first cover the famous **Gauss-Markov Theorem**, which is where these assumptions come from. Then we'll discuss each assumption in turn.\n",
    "\n",
    "### The Gauss-Markov Theorem\n",
    "The Gauss-Markov Theorem is named after Carl Friedrich Gauss and Andrey Markov.\n",
    "\n",
    "Let the regression model be: $Y={ \\beta }_{ o }+{ \\beta }_{ i }{ X }_{ i }+\\varepsilon$\n",
    "\n",
    "Under the Gauss-Markov Theorem, the model specified above is the **Best Linear Unbiased Estimators (BLUE)** if, and only if, several assumptions are satisfied. BLUE merely means that the estimated $\\beta$ coefficients have the minimum variance of all linear and unbiased estimators of $\\beta$. This venn digram illustrates:\n",
    "\n",
    "<img src=\"assets/blue.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The linear regression model is “linear in parameters.”\n",
    "Consider an equation of the form:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "where $x$'s are the variables and $\\beta$'s are the parameters. Here, $y$ is a linear function of $\\beta$'s (linear in parameters) and also a linear function of $x$'s (linear in variables). If you change the equation to\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x_1 + \\beta_2x_1^2 + \\epsilon\n",
    "$$\n",
    "\n",
    "Then, it is no longer linear in variables (because of the squared term) but it is still linear in parameters. And for (multiple) linear regression, that's all that matters because in the end, you are trying to find a set of $\n",
    "\\beta$'s that minimizes a loss function. For that, you need to solve a system of linear equations (like we did above).\n",
    " \n",
    "To get a better understanding of this, we'll simulate some data with a non-linear relationship between $x$ and $y$. Then we'll fit an OLS non-linear curve that's nevertheless linear in its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.947\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     275.9\n",
      "Date:                Fri, 19 Apr 2019   Prob (F-statistic):           2.10e-29\n",
      "Time:                        07:46:38   Log-Likelihood:                -26.947\n",
      "No. Observations:                  50   AIC:                             61.89\n",
      "Df Residuals:                      46   BIC:                             69.54\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.4698      0.023     20.666      0.000       0.424       0.516\n",
      "x2             0.5566      0.089      6.228      0.000       0.377       0.736\n",
      "x3            -0.0182      0.002     -9.138      0.000      -0.022      -0.014\n",
      "const          5.1359      0.147     34.845      0.000       4.839       5.433\n",
      "==============================================================================\n",
      "Omnibus:                        0.156   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.925   Jarque-Bera (JB):                0.349\n",
      "Skew:                          -0.079   Prob(JB):                        0.840\n",
      "Kurtosis:                       2.623   Cond. No.                         221.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "nsample = 50\n",
    "sig = 0.5\n",
    "x1 = np.linspace(0, 20, nsample)\n",
    "X1 = np.column_stack((x1, np.sin(x1), (x1-5)**2, np.ones(nsample)))\n",
    "beta = [0.5, 0.5, -0.02, 5.]\n",
    "\n",
    "y_true = np.dot(X1, beta)\n",
    "y1 = y_true + sig * np.random.normal(size=nsample)\n",
    "\n",
    "res = sm.OLS(y1, X1).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll graphically compare the true relationship to the OLS predictions. This is commonly called a **residuals-vs-fitted plot**. This graph shows if there are any nonlinear patterns in the residuals, and thus in the data as well. One of the mathematical assumptions in building an OLS model is that the data can be fit by a line. If this assumption holds and our data can be fit by a linear model, then we should see a relatively flat line when looking at the residuals vs fitted.\n",
    "\n",
    "If the relationship is nonlinear, the residuals will have non-random patterns.\n",
    "\n",
    "Confidence intervals around the predictions are built using the `wls_prediction_std` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prstd, iv_l, iv_u = wls_prediction_std(res)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(x1, y1, 'o', label=\"data\")\n",
    "ax.plot(x1, y_true, 'b-', label=\"True\")\n",
    "ax.plot(x1, res.fittedvalues, 'r--.', label=\"OLS\")\n",
    "ax.plot(x1, iv_u, 'r--')\n",
    "ax.plot(x1, iv_l, 'r--')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, you can use the Rainbow Test for the Null hypothesis that the linear specification is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t value', 0.9912127048425328), ('p value', 0.5131894359928766)]\n"
     ]
    }
   ],
   "source": [
    "name = ['t value', 'p value']\n",
    "test = linear_rainbow(res)\n",
    "print(list(zip(name, test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Error term has zero population mean\n",
    "This is sometimes phrased as the errors having a [conditional mean](https://en.wikipedia.org/wiki/Conditional_expectation) of zero: \n",
    "\n",
    "$$\\operatorname{E}[\\,\\varepsilon\\mid X\\,] = 0$$ \n",
    "\n",
    "In other words, each observation should have random error with a mean of 0. This is of couse rarely the case, so that's why a constant term (the intercept) is added to the OLS model. It takes the amount of error that deviates from 0, lallowing us to say $\\operatorname{E}[\\,\\varepsilon\\mid X\\,] = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Error term is not correlated with Xs\n",
    "This is often referred to as **strict exogeneity**, meaning that your independent variables are determined outside of the model. If this assumption is violated, the real cause of changes in your dependent variable might end up in your error term and then inflate (or deflate) the coefficient for one (or more) of your coefficient estimates.\n",
    "\n",
    "As an example, take this simple OLS model:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_{1}X_{i} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "Suppose $X_i$ and $\\epsilon_i$ are positively correlated, i.e. when $X_i$ is large, $/epsilon_i$ tends to be large. In this case, your plotted line might look like this:\n",
    "\n",
    "<img src=\"assets/exog.png\" width=\"300\">\n",
    "\n",
    "Why would $X_i$ and $\\epsilon_i$ be positively correlated? And how could that cause your estimated coefficient for $X$ overshoot the true value? As an example, pretend our $y$ is quantity of hamburgers sold across the county and our $X$ is the price of those hamburgers. Our model would be:\n",
    "\n",
    "$$\n",
    "sales_i = \\beta_0 + \\beta_{1}price_{i} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "The problem with this model is that it's omitted (at least one) very important variable:  **quality**. It's quality much more so than price that drives a person's decision to buy a 1 dollar burger from McDonalds as opposed to a 20 dollar burger from a fancy gastropub. By not including this variable in the model, its effect becomes a part of $\\epsilon_i$. Unfortuntely, price and quality are highly correlated. Therefore $x$ and $\\epsilon$ are highly correlated. This means the estimate of $\\beta_{1}$ will be too high, as you can see in the plot above. \n",
    "\n",
    "You can easily calculate the correlation between your error and Xs like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -2.1271246713672138e-13 1.0\n",
      "2 -2.164611624876811e-13 1.0\n"
     ]
    }
   ],
   "source": [
    "error_term = results.resid\n",
    "for col in range(X.shape[1]):\n",
    "    if col == 0:\n",
    "        continue\n",
    "    _X = X[:,col]\n",
    "    r, p_value = pearsonr(error_term, _X)\n",
    "    print(col, r, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. No serial correlation\n",
    "Serial correlation (also called autocorrelation) occurs when the error terms across observations are correlated with one another (i.e. $\\epsilon_1$ is correlated with $\\epsilon_2$). the errors are uncorrelated between observations: $E[\\epsilon_i \\epsilon_j \\mid X] = 0$ for $i ≠ j$. \n",
    "\n",
    "\n",
    "If errors are serially correlated like this, then the error in one period affects the error in the next. This is important to check for in time series data, panel data, cluster samples, hierarchical data, repeated measures data, longitudinal data, and other data with dependencies. In such cases generalized least squares provides a better alternative than the OLS. Another expression for autocorrelation is serial correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Homoscedasticity\n",
    "The error should have a constant variance: \n",
    "$$E[{\\epsilon_i}^2\\mid X] = \\sigma^2$$ \n",
    "\n",
    "This means that the error term should have the same variance $\\sigma^2$ in each observation. When this requirement is violated we have heteroscedasticity (i.e. the variance of the error depends on $X$). In such cases a more efficient estimator could be weighted least squares. If the errors have infinite variance then the OLS estimates will also have infinite variance (although by the law of large numbers they will nonetheless tend toward the true values so long as the errors have zero mean). In this case, [robust estimation](https://en.wikipedia.org/wiki/Robust_regression) techniques are recommended.\n",
    "\n",
    "A good visual way to check for heteroscedasticity is with a Scale-Location plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model values\n",
    "model_fitted_y = results.fittedvalues\n",
    "# model residuals\n",
    "model_residuals = results.resid\n",
    "# normalized residuals\n",
    "model_norm_residuals = results.get_influence().resid_studentized_internal\n",
    "# absolute squared normalized residuals\n",
    "model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "# absolute residuals\n",
    "model_abs_resid = np.abs(model_residuals)\n",
    "# leverage, from statsmodels internals\n",
    "model_leverage = results.get_influence().hat_matrix_diag\n",
    "# cook's distance, from statsmodels internals\n",
    "model_cooks = results.get_influence().cooks_distance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmcHGWZ+L9P9/TcRzKZyWRyTCb3yZkAIsodxQvEA2U9EEEW12PXVXfdwwPc3R8qK96yWY2A7oJgFFjEYBA1IocQCJCDhMl9TJJJJnNmjp6Z5/dHVc/0dHpmuquru6q73+/nU5/urq6ueuro93mf431eUVUMBoPBYEiEgNcCGAwGgyF7MErDYDAYDAljlIbBYDAYEsYoDYPBYDAkjFEaBoPBYEgYozQMBoPBkDBGaRgMMYjIR0TkSa/lcIqI3CkiX/RaDkNuYpSGIesRkTeIyFMi0i4irSLyZxE5xyNZLhaRAxk83ikKTlVvVtWvZkoGQ35R4LUABkMqiEgl8AjwceB+oBB4I9DnpVwGQ65iLA1DtrMQQFXvVdVBVe1R1d+q6ssAIvIxEdkmIp0islVEzrbXf0FEdkatv3qsA4jIYhFZb1sx20XkGieCikiViNwjIi0isldE/lVEAlHfJyWriCwB7gTOF5EuEWmz198lIv8Ws98mW/6HRWR61HcqIjeLyGsi0iYi3xcRcXJ+hvzAKA1DtrMDGBSRu0XkLSIyOfKFiLwX+ArwYaASuBI4bn+9E8siqQJuAX4mIvWxOxeRMmA98L/AVOD9wA9EZKkDWb9rH28ucJEt1/VOZVXVbcDNwNOqWq6qk+LIfynw/4BrgHpgL3BfzGZvB84BTre3e7ODczPkCUZpGLIaVe0A3gAo8N9Ai92brgNuBL6uqs+pRZOq7rV/94CqHlLVIVX9OfAacG6cQ7wd2KOqP1HVAVV9EVgLvDcZOUUkiKVw/klVO1V1D/CfwIfsTdyQNR4fANao6guq2gf8E5Zl0hi1zW2q2qaq+4DfA2cmc26G/MIoDUPWo6rbVPUjqjoTWA5MB74FzMLqpZ+CiHxYRDbZLpk2+3c1cTadDZwX2c7e9gPANBFpsN1CXSLSNYGYNUAIq6cfYS8ww37vhqzxmB59TFXtwrJgZkRtczjq/UmgPMF9G/IQEwg35BSq+qqI3AX8NbAfmBe7jYjMxrJKLsNy7QyKyCYgni9/P/BHVV01xiETbWCPAWEsJbTVXtcAHIw6jhNZJypTfcg+ZmR/ZcCUqOMaDElhLA1DVmMHqT8rIjPtz7OAa4FngB8BnxORFWIx326Ey7Aa2xb7N9dj9d7j8QiwUEQ+JCIheznHDkKPJ1dx9AIMYWV3/buIVNhy/D3wM/snTmU9AswUkcIxRLkXuF5EzhSRIuA/gGdt95jBkDRGaRiynU7gPOBZEenGUhabgc+q6gPAv2MFsTuBB4FqVd2KFU94GqvRPQ34c7ydq2on8CaseMQhLFfO14CicWSaAfTELPOATwHdwC7gSVuuNfZxnMr6BLAFOCwix+LI/zjwRaw4TLMtx/vHkd1gGBcxkzAZDAaDIVGMpWEwGAyGhDFKw2AwGAwJY5SGwWAwGBLGKA2DwWAwJEzOjdOoqanRxsZGr8UwGAyGrGLjxo3HVLV2ou1yTmk0Njby/PPPey2GwWAwZBUisnfirYx7ymAwGAxJYJSGwWAwGBLGKA2DwWAwJIxRGgaDweBTPvrRjzJ16lSWLx8pN/bSSy9x/vnnc9ppp/GOd7yDjo4OAPbs2UNJSQlnnnkmZ555JjfffHNaZDJKw2AwGHzKRz7yEdatWzdq3Y033shtt93GK6+8wtVXX803vvGN4e/mzZvHpk2b2LRpE3feeWdaZDJKw2AwGHzKhRdeSHV19ah1O3bs4MILLwRg1apVrF27NqMyGaVhMBgMWcSyZct46KGHAHjggQfYv3//8He7d+/mrLPO4qKLLuJPf/pTWo6fc+M0DAaDIZvZ1tzOus1HONjWw4xJJZxW1Tvq+zVr1vDpT3+ar371q1x55ZUUFlpTqdTX17Nv3z6mTJnCxo0beec738mWLVuorKx0VT6jNAwGg8EnbGtuZ/WG3VSVhKivKqa9J8z/vnqAvoGh4W0WL17Mb3/7W8ByVf36178GoKioiKIia5qXFStWMG/ePHbs2MHKlStdldG4pwwGg8EnrNt8hKqSEFUlIQIiVJWEqCwuoKt3YHibo0ePAjA0NMS//du/DWdJtbS0MDg4CMCuXbt47bXXmDt3rusyGkvDYDAYfMLBth7qq4qHP//0P/6eppf/Qnf7CWbOnMktt9xCV1cX3//+9wF417vexfXXXw/Ahg0b+NKXvkQoFCIQCHDnnXeeEkR3g5ybuW/lypWartpTvb29XHjhhfT19TEwMMB73vMebrnlFr73ve/xrW99i507d9LS0kJNTU1ajm8wGHKbO9bvoL0nTFVJaHhd5PNnVi1M67FFZKOqTujLMu6pJCgqKuKJJ57gpZdeYtOmTaxbt45nnnmGCy64gMcff5zZs2d7LaLBYMhirlheR3tPmPaeMEOqw++vWF7ntWjDGKWRBCJCeXk5AOFwmHA4jIhw1llnYcqxGwyGVFlSX8VNF86hqiREc3svVSUhbrpwDkvqq7wWbRgT00iSwcFBVqxYQVNTE5/4xCc477zzvBbJYDDkEEvqq3ylJGIxSiMBYvOm7/3NH6kvUa6++mo2b948qi6MwWAw5DLGPTUBkbzp9p7wcN706g27ae4RLrnkklPqwhgMBkMuY5TGBETnTZ9sP0HhYA9VJSEe3riX9evXs3jxYq9FNBgMhoxhlMYEHGzroaLY8uJ1tB7lB5//MKv/7l1842/exapVq3j729/Od77zHWbOnMmBAwc4/fTTufHGGz2W2mAwGNKDGacxAV7mTRsMBkOm8P04DRFZIyJHRWTzONtcLCKbRGSLiPwxk/JFyIa8aYPBYMgUXrqn7gKuGOtLEZkE/AC4UlWXAe/NkFyjyIa8aYPBYMgUnqXcquoGEWkcZ5O/An6pqvvs7Y9mQq54+D1v2mAwGDKFnwPhC4HJIvIHEdkoIh8ea0MRuUlEnheR51taWjIoomEs4s1t3NrayqpVq1iwYAGrVq3ixIkTADz00EOcfvrpnHnmmaxcuZInn3zSK7ENBsME+FlpFAArgLcBbwa+KCJxI8+qulpVV6rqytra2kzKaBiDeHMb33bbbVx22WW89tprXHbZZdx2220AXHbZZcP1vNasWWOyzwwGH+NnpXEAeExVu1X1GLABOMNjmQwJEm9u44ceeojrrrsOgOuuu44HH3wQgPLyckQEgO7u7uH3BoPBf/hZaTwEvEFECkSkFDgP2OaxTIYUOHLkCPX19QBMmzaNI0eODH/3q1/9isWLF/O2t72NNWvWeCWiwWCYAM8C4SJyL3AxUCMiB4AvAyEAVb1TVbeJyDrgZWAI+JGqjpmea/CeieY2jkZERlkUV199NVdffTUbNmzgi1/8Io8//ngmRDYYDEniZfbUtQls8w3gGxkQx5AiicxtXFdXR3NzM/X19TQ3NzN16tRT9nPhhReya9cujh07ZiazMhh8iJ/dU4YsIpG5ja+88kruvvtuAO6++26uuuoqAJqamohUJnjhhRfo6+tjypQpmT8Jg8EwIaY0usEVEpnb+Atf+ALXXHMNP/7xj5k9ezb3338/AGvXruWee+4hFApRUlLCz3/+cxMMNxh8iqk9ZXAFU6PLkIvExumuWF6XswN9fV97yk9sa27njvU7+NwDL3HH+h1sa273WqSsw9ToMuQaY82lk+/tQ94rDfNguIOp0WXINeLF6apKQqzbfGTiH+cweR/TiH4wgOHXdZuPJNzg5ZMJOx6mRpchl4iN0wFUFBdwsK3HI4n8Qd5bGtGTLEVI5sEwlorBkJvMmFRCZ1T2H0Bn7wAzJpV4JJE/yHulkeqDYUxYgyE3MXG6+OS90oh+MI509PCH7Ud54tWjHOvsTchaSNVSMRgM/sTE6eKT9zGNyIPx06f38vvtLaBQWhRk86EOvr5uO/9wxaJxH5IZk0pOSTVNlwlrYicGQ2YxcbpTyXtLAxh+KMoLC5hWVUxteREA+46f5KdP7x33t5kyYU3sxGAw+AGjNGxe3N9GeVGQ4lAQEaE4FKS8KMiL+9vG/V2sCds/MEhpKMCPn9zj6pgPEzsxGAx+YEKlISKDmRDEawQhdmy82usnYkl9FZ9ZtZAb3tBIT3iIUEHQdWvAxE4MBoMfSMTSyIsiQGfNqqKrb5De8CCqSm94kK6+Qc6albg/M53WgEn/MxgMfiCRQHhuFacagw+eP5vDHX0c6+qjozdMUUGQOTVlfPD82QnvI52Dga5YXsfqDbuH99nZO0B7T5j3nTMz5X1nIyYpwGDwhrzPnoqwpL6Kz715YUoNUTozqSKxk2j53nfOTM8bSi8a73hzd6zesNukQxoMGSAppSEiDQlu2qaqHRPsaw3wduCoqi4fZ7tzgKeB96vqLxIW1gGpptel2xrwW/qfV423G6VfDAaDM5K1NO4mEh8eGwXuAu6ZYF93Ad8bbzsRCQJfA36bjJBe4VdrIF141XibmkAGg3ckpTRU9RK3DqyqG0SkcYLNPgWsBc5x67jpxm/WQDrxqvHO5IBKg8EwGkfjNERkg4hU2u9vFpG/E5FCNwUTkRnA1cAPE9j2JhF5XkSeb2lpcVOMnMSt+UO8yugyNYEMBu9wOrivSlU7RGQF8DFgMvDf7okFwLeAf1TVoYk2VNXVqrpSVVfW1ta6LEZu4ebIcq8ab1MTyGDwDqfZU2ERKQA+DHxNVe8XEbfnWF0J3GfPFV0DvFVEBlT1QZePk1e4GYdINIaTjgyrfHIDGgx+wqnS+C7wElAMfMFeV+6KRDaqOifyXkTuAh4xCiN13I5DTNR4m/RYgyG3cKQ0VPVuEVkLDKpqj4jMx0qLTRgRuRe4GKgRkQPAl4GQvf87nchlmJhMB5HdzrAyg/oMBm9JdpzGT4EXsayMTap6HEBVm4Drk9mXql6bxLYfSWbfhrHJ9MhyNy0bY7UYDN6TrKXxE+AM4EPA7XYG1TZGlMgDLstncJlMjyVx07Ixg/oSw1hjhnSS7DiNJ4AnIp/tYPgSLEVyLmCURhaQySCym5aNGdQ3McYaM6Qbp+M0pojIx7EsjhJgrap+3lXJDDmBm+mxptLvxJh5Vwzpxmn21K+Ax4GPAzuA80Vkp6oucU0yH2HM/dRwy7Lxa6VfPz0fxhozpBunSqNCVW8VkXep6kUi8m4sF1XOMZa5f/mSWnYc6fZFQ5Ev+LG2l9/cQabEiiHdOFUavfZrn4iUqOpaEfk88CWX5Moo4/UU4wVfW7v6+O4TO3nd3Cm+aCjyCb8N6vNbcN6v1pghd3BaRuR2EakGfg6sEZFPAZPcEytzTFRWI940q4c7egkPDhm/scF30/CaEiuGdON0cN9a++03ReRDwGnAu1yTKoNM1FOMZ+63doeZUja6PqOXDYWffOqJkG3yjocf3UF+s8YMuYUjpWHXmXoJeMVe1qlqVpaXnShwGM/cLwjIKb+JbShiG8aFdWVpiYH4zac+Edkm70QYd5Ah33DqnroSa0xGIfDXwB4R2euaVBlkojTOeOb+py6bRyAQGLO6a6zLa3dLF7f9Zjt7jnWlXFk2lmxLscw2eSfCuIMM+YZT99Qh4BCwDkBElgDvcVGujJFITzGeuT+3tnzMLJ5Yl9fhzj7Kigo43NFHY025q8HSbEuxzDZ5E8G4gwz5hFP31GxVHbYsVHWbiCx0T6zM4TSNc7yGIrZh7OodoKIoSEdveHidWw2lH33q45Ft8hpyj1yKqXmB05Tbe0WkAdiNFdNoA5a7JlWGcbunGNswlhcX0JGmhjLbfOrZJq8hedLdKKey/1yLqXmBo5iGqr4emIVV2XY9sBN4h4tyZTWxM9pNqyiiu2+AaZVFrs9wl20+9WyT15Acbs4MmY7951pMzQuSLY3+VqxqtodUVYEme8l63Owdxbq85tSW8+bldaOyp9wcyRxrKUXmAPer+Z2pGEC2uyGyUf50D3ZMdf+xruOWzl6ajnZxpLMPICuusdck6566GrhVROqAV7FLotuvW1V10GX5MkI6TNZ4DePb3BB2Aoz5bZHt1yFb5U93okOq+492Hbd09vLCvjYA6iqKsuYae01S7ilV/ZiqrgR+iFWocBdwCfAskFTKrYisEZGjIrJ5jO8/ICIvi8grIvKUiKSttlWsydo/MMiuli4+e//L3LF+h2umdSYw5rdFtl+HbJU/3ZWIU91/tOu46WjX8PoFdeVZc429xuk4jfep6idU9QeqegPwRuDJJPdxF3DFON/vBi5S1dOArwKrHUmaANGlIIZ7H6oM6ZDrPtl047eyFl7h1XWIuAY/98BLKXU4svU+xsbz3IzfubH/6Jjakc4+KosLWDF7EjXllvWSDdfYa5wqjQ4RWRH5oKobgaRSblV1A9A6zvdPqeoJ++MzQNrSa6J7L00t3RQVBECEqpLCrOt9mDknLLy4Dm4GgbP1PqY70cGN/S+pr+IzqxbyzjNnsHR61bDCgOy4xl7jNOX2BuCXIvIcsBGr9lR4/J+kxA3Ab8b6UkRuAm4CaGhoSHrn0WmgnT1hQkGhf1BZPqMSyK7eR7pSWr0Myjo5thepvW4GgbM5NTndiQ65Pj+L33GacrsDOBurIa/Dmif8rS7KNYyIXIKlNP5xHHlWq+pKVV1ZW1vr6DgloQDP7j5OS1cffeEhVsyehCo8ves4v3nlMPtaT2aFiyodPb10p1Gm49hepPa66VIyqcnpx1xjZySbcvsVVf2KiFwAvKyq9wP3p0c0EJHTgR8Bb1HV4+k4RnSWyuVL6th7rJsX97dxsPUkhzv6QSAYgPrKopQzK+L1mAHXe/Bu9/S8nDMilWNnuryH26PdTWpy+jElYJInWffUY/br3wLLRSQEbAVexlIiD7glmD3i/JfAh2zLJi3ENkpzassBeH7fCUpCQWrKi5g/tYyacquX67ShjJdC+fV12wmIMKu61NdplV7Wi8qmWlVeuzucNP7Zmtpr8I5kU26ftl+vUdWlWKVDbsEa4HdeMvsSkXuBp4FFInJARG4QkZtF5GZ7ky8BU4AfiMgmuxy768RzKcyuKSMUDPDW0+p53dwprmRWxEuhbO3u51hXn+/TKr0MymZTQNhLd4dTN162pvYavMNpwcINwNtVtUNEzgWKgX9OZh+qeu0E398I3OhEvmQYy6VQV1lMZ+9A0q6GsXp78XrM/QNDKDpqnRe96Il6qF72oL3uvSeLV+4Op268bLLkDP7Aacptla0wVgAfAyYD/+2eWJkjkve9u6WLp3ce49cvN/PMzuNctrgm6Xzw8Xp78XrMhQUBigqCo9ZluhedSA/Vyx60CVYmhtMgfDZZcgZ/4DTlNiwiBcCHga+p6v3pch+lmyX1VVy+pJbvPrGT8OAQU8oKqa8q5tXD3Vy+pDapelHj9fbi9ZirywoJiLC7pYvDHb20docpCAifumxeWs41nkWRaA/Vy4ChCVZOjNMgfLZZcgbvcao0votVb6oY+IK9rtwViTxgx5FuXjd3yqg/XHtPmB1HuvnMqsTHLI5n6sebt+MfrljErpauUxTW49tamFtb7no56XgBz66+MIunVcaV2ZA9OG38nc4nY8hfnM7cd7eIrAUGVbVHROZjBbWzErf8uhP19uL1mNdtPnKKwtrd0sWXH95KQ3WpaymQY1kUB9t6HMVuDP4ilcbfWHKGZHAaCF+AZWH0AJ9U1SasuTWyErfy65309uKVat5xpIvw0BDnzal2LQVyLMVYWVxAe084KZkN/sQ0/oZM4DQQ/lPgF8CFACKyXETucU2qDBOvCNre490c6+xNqvCck6BtbCCyqaUbBGrKi1xNgRwr4Llsugk0ZxK3ChoaDF7hNKYRUNXfiMh/AKjqZhHJ6uleo037wqAQECFUEKS6vCCp3n6yvb1Y66S1q59gAOZPLRvexo0Yw3hWkOmhZgYzkM6QCzi1NA6JyBywBhmIiABZ7QSPVL68/b1nUFtRzKzq0owMeIq1TqrLC1k8rcL1ypsmddV7zEA6Qy7g1NL4O6yaUNNE5HqseTHiTqaUjWxtbqf9ZJjOvgEqi0PMn1pGdVlR2jKKonv60eMmoi2CcxonOZ7CNTbV9oY3NBpl4QFmIJ0hF3Ba5XYPlqL4NDAX+CPwIffE8o5tze3sP95DR+8AFUUF9IYH2bi3jX3HuzOSURTPIrh8SS2Pb2txVGU21Qq1xgfvHmYgnSEXcGppoKoDWMHwX7gnjves23yEhXXl7DjaRd/AEEUFAfoGhth+pIubL07PoLtYYmMMd6zfMeEAvLFKgaRSJTYTPvh8qrBqBtIZcoGkLA0R+ZCItNgFBq+z171ORL4qIhvTI2JmOdjWw+yaMs5umERRKEhX3yCVxQXMnFziWWM2UYmI8ayJVOZ4SLcP3st5OiaSKx3WlYkrGXKBZC2NL2FNtrQb+KSIrAeWAP+LFefIeiJjNmoriqmtsPzPsWM4vJJprHEk41kTqYxBSbcP3st5OsYi3daVyVQzZDvJKo0uVX0OQERuAY4AC1W1zXXJMki0i6QwKBzp6IPqUscuBLddLhO5NcZr3G94Q6Njl4jbkwrF4sfAsB8VmcHgJ5INhE8TkZtE5CKsaV4P5ILCiHaRFBYEGVIlPDDoyIWQDpfLRG6N8QKsqbhE4g16nKjSbzL4MTDs5pStBkMukqyl8WXgNOAD9muFiDwOvAi8qKr/67J8aSdez3L2lDKqSkJJFSscb3+R9W5OE5vMfBfJuERij5Vspd9k8GNgON3WlcGQ7SSrNA4Aj6jqIQARmYmlPE7HinUkrDREZA3wduCoqp4ymtweMPhte78ngY+o6gtJyjshbrtI3N5fIj52p8XqYhXEwroyHt/WMupYj29rSVuw1o8VVv2oyAwGP5Gs0rgauFVE6oBXscqjbwIeBW5Pcl93Ad8DxqpZ9RZggb2cB/yQJKeUTYTYnmVLZy9bDnUQHlTuWL8j6XiE2z3VdM13EU8Zffd3O1k0rTyj/nw/BYYjSrSzN8zBth6qSgpYWl/luSIzGPxEsnOEf0xVV2I14DuAXcAlwLPA3iT3tQFoHWeTq4B71OIZYJKI1CdzjESI9tsf6ejh2V2tdPYOcMasSkfxCLfjAOnyscdLpx0YUprbe10/VjYQHYtaUl/J0vpKyotCOT1uxGBwgtPBfe9T1TMiH0TkB8Dn3RFpmBnA/qjPB+x1zbEbishNwE0ADQ0NSR0kMnPf3U/vY/vhDooKAqycPZmpFSOWQTI9bbddLunyscdzo1WXhTje3T9qXb74803WlPvk08DNfMKp0ugQkRWquhFAVTeKSPJRY5dQ1dXAaoCVK1dqMr/d1tzO49taWFpfSWdPmFBQ2HXsJJPLCqkpL3bU046tJbVu8xF+/OSe4bhBdGB5oj9Sunzs8ZTRtMpiOuz955s/34/pv6niZaNtKvrmLk6r3N4A3C0iPxGRT4rIfwFhF+UCOAjMivo8017nKtE9zIqSECJCUUGApqPdQGo97dj0290tXdz2m+3sOdaVcDpuukYRx3OjBYMBPnXpvLwcsezH9N9U8Hq0vanom7s4ne51h4icDbwTK3tqG/DPbgoGPIw16vw+rAB4u6qe4ppKlege5vzaMl7Y10ZRUGjv6R9uVJ32tGNdHoc7+ygrKuBwRx+NNeUJu0DSESwez432NlePlB3kWtaU1+62RCw3477KTlKd7rVXVT/hcB/3AhcDNSJyAGsMSAhAVe/Eysh6K9CElXKblulko900tRXFnN0wiS2HOghIgKqSUErxiNg/TlfvABVFQTp6R4yyZF0g8dJkk3F3ReOnzCWv8WP6byp47W6bKBZn3FfZi9OYxk+BW4CvgTXdK/APqvrhRHegqtdO8L0CjhRSMsT2MAsLglSXFTK9qpiDbT3D5vRE1WTjEfvHKS8uoCPJoHa8EiezqkuH3V2/fOEAZzdMomFKmet/PK96gl4dN5eUqNeDFCey3Ly2hAzOcRrTCKjqb4BBsKZ7BbJyutfYmEH/wCABETp7B9h3vJtfv9zMZ+57iV+/fHBCP3FsddSFdWWj4gbTKoro7htgWmVRQum4scfbcqiD3ce6CQ9aMka7u9z2G3vlE/faF58rpLsEzERMFIsz5VqyF6eWRk5N9xrdw7xj/Q66egfYcbSLooIA1WUhOnoH+Ma67VQUhzgZHqSmvIj5U8uGp2SNNNKx5vbj21pGleGYU1vOm5fXJVyWI7Y3Fh5UyouCNB3tpqa82BV311h41RM0PVB38IO7bTzLzWtLyOAcM91rDAfbejjc0UtRQYDiUJDuvgGOdfbS1jNAQaCPebWlw7P5rZg9aXga2LEaux1Huk+pYZVooDnWL11eXEBf/8CwknDi7koUr3ziXvvicwk/u9tyLfEgnzDTvcYwY1IJrd1higoCdPcN0NzeS3f/IIVBAeBgWx9DqsNpuZFGOp653Rse4LdbDzuezCc2DXR+bRldfYMUBgOO3F2pHBsy0xPMtdRXQ3zMhFTZi9PsqfcAa1U1d6Z7PXkShoa4YtlUHtt8mI7eATp6wggwpFBWGCAYEMJDcLD1JMWFQTp7B2k/GeZTl1nTwMbWsHpu9wnKiwtOyQ4BEgr0xgvSN0wpZXpVMc3tvUm7u5LBq56g6YHmD362hAxjI1aS0jgbiAyqajBmXQ/wIPBBVR20112vqj9Jm6QJsnLlSn3++eeT/+GDD8I3vwm9vRwLFLH9pNASKKavtIyOwlI6C0sprJ5Ea7CY/YMhessqGCovZ8H86fSVV/KGsxp5fPtxa5BgcQEbdrTQ2TvA+fOqh2Mf7T1h+gcG6QkPDW8XaRTH6mW5lUnkZD/5lj2VDnLpXAy5jYhstGsLjr+dQ6XxIvBfWC6q96pqWEReUNWzUxHaDZwqjcifu/l4J42hQRaXDvHoU68x0HqCSQO9FHR2MGWol4G2dsp6upky1EtDMExFfw/Brk5K+nuomFLFYS3kRKiU5qEQ5VMnUzB5Mv2l5fSVVdBbVsGTxwaYu2AmoZqELyV7AAAgAElEQVQp9JVXMVhYOGyhOJm/I9FziwTpE1FUXpCLjWs2XHe3yMX7l28kqjScBsJVVe8UkZPAwyLyLkAc7stzov/cddXlHO0d4LWOMJe/91Ie39YCJSG6wgM819xJ09Eu5kwp5YyGSeyyLYghVQ6fOMk33jKPee3t0NnJfetfoe1EO9UDJ+lrbaN7xx4C7W28rrOdhRvDVPWdpKirAw0G6S2r4ERROfzfHJg8eWSZNGn06+TJUFYGktyl9ntGUq4O9PL7dXeLXL1/45HPStKp0jgBoKr32K6qXwOlrkmVYcbLfIqkLXb1DXDxoqksn15JqCB4SsbS9OoyqKy0FuCMyTNYvWE3g4ND7DjSBQshYtWFB9VyW5UVUdDXS/+x49SGT7JySRWcOAFtbdbr7t0j7yPr+/tHK5FJk0Ypl71DhTx5bJB9Q4VUTZ/KJefN931Gkl8b11QbBr9fd7fw6/1LF/moJKNJSmmIyFdU9SvAl0WkQlU7VfUB2+K4Oy0SZoDx/tyxwbrIAxPZZqxAbSQ75MsPbyU8NDQ8tkMVnt3VyuaDHVy4sJbjWkB7aTVvvXAFJPLA9fePKJGIIrEVy9EXXmHnln0s7utmZU8nBR3tFHR18vGSUvrLKxmsqqKvrJK+8kraispYOnkylOw/1bIpyWymkh8bVzcahlwdixCrTLc2t7N4WuWobby+f+kk35RkLMlaGo/Zr58GlotICNgKvAx83E3BMkn0n7uls5emlm5au/qpLi9kW3P7KTPkJTpoakl9FQ3VpZw3p5pAlEvpnDmTeelAO83tvclnPBUWQl2dtcTwP+t30H7+6Eaqo7sPOjuQtnamDvZQ3d/F0Ik29MQJLi3ph7/8ZbQSOnHCcn9VV0NtLcyeDQ0N1uvs2TBrliWDi2SqcU3GcnCjYcjFTLB4ynT/8R5KQ0Eaa8qHt8sF5TgWfuzkZJKklIaqPm2/XgMgIkXAMqxKt+cCD7gtYCaI/Llbu/osV5JAMAD1lUVxe5fJpArGaxCLQwW8aek01wPf8R7m8tJCmsPl3PCe5azbfIS/tPUw4yyrwayLdw6q0NNjKY8jR2DvXti3Dx55xHrf3Aw1NZYiaWiAxsYRpVJXB4Hkh/5konFN1nJwo2Hww6hst4mnTBfWlbP9SBeTy4pyRjmOR65akImSrHvqrcAmVT0EoKp9wAv2krWM5UqqKbcal1TMzkz2Nsd7mBNWdCJQWmotM2bA2TEJcYODcPCgpUj27YOmJnjiCet9WxtMnw4zZ566TJ8+poWSicY1WcvBrYYh18YixCrTls5eDnf00nayn63NHXkxr3ouWpDJkKx76mrgVhGpA14FXgI22a9bI2M2spGxXEmR3qXToGiiDaIb2RgZeZiDwRErI5aeHkuhHDhgLXv2wJNPWu+PHLHcXfPmwfz5I8vs2VBQkPbGNVnLId613Hu8m+lVxXzugZfyLmMmQqwr94V9bQA0VJeytL5yuCJBLl+XXLQgk8HpOI1/xpqvewuwArgWaFVVz1Wt48F9WMUKY3uXTgbkJcJYJc9T3X9kv1sOtdPROzDc8/P8jxyxUJqaRi+HD1sKaMECWLgQFi2y3k+e7Orhx7q3442PSdc9ymai3Xxb7WcMYMXsScOWeTrHHBnSR7rHabxPVc+IOtgPgM873JdvGKunXhoKuJotEetfj4wen1ZVREBCKe0/sv2+1pPMnGw1cL5ICYy2UC69dGR9Xx/s2gWvvQY7dsCf/mS9lpZaymPRIkuZLFxoubkcxEzAmRUWW/24MCrVOt8yZiJE97KPdPZRV1HEgrry4aoH+RQQzlecKo0OEVmhqhsBVHWjiCTdtRCRK4BvA0HgR6p6W8z3DVipvJPsbb6gqo86lHlCxjI7f/zkHqrL3av9P1HJc7f37+sGrqgIliyxlgiqVsB9xw5r+c1v4DvfsWIm8+ePKJGFC63PxaPdTmO5+lJxKeR7xkw00co0nwPC+YpTpfFR4Fci8hywESt7Kjz+T0YjIkHg+8Aq4ADwnIg8rKpbozb7V+B+Vf2hiCzFmgK20aHMCRHPt+52tsREJc/d3j9kWQMnYgXOp0+Hiy8eWd/RYbm0tm+HV16BtWutuEl9/bBra8/ken52tJDQ1Nq4WVJOlWa+Z8zEI98DwvlK0kpDRALAe4GzgXdiKYxtwD8nuatzgSZV3WXv9z7gKqxxHxEUiIwaqgIOJSuvG0T/OXrDA2xr7uTEyTBvnD/llHEciRDbAM2vLePZXa2UFxcwpJryny9nG7jKSiubKzqjKxy2FIdtlbT/Yh037t1FIBSiddYc2mY0cqB2Fk/1HWfJBy/JqHsr18n3gHC+4jQQ/pSqvj6lA1vl1a9Q1Rvtzx8CzlPVT0ZtUw/8FpgMlAGXR1xiY5FKIDyaWBfHwroy/tx0nCebjjO5NMTS6RUUFRQ4CobGK2QXyczpG9SUM3PyqVBeLJ974CXqK4sob29l8v7dTDq4h8kHdlOyeyfLi8LWuJJ580ZncdXWJlTPK5/rDWUSc529Id1Vbu8EmoFbdaIdjL3fRJTG39sy/qeInA/8GFiuqkMx+7oJuAmgoaFhxd69e5OWJ5FMmdJQ4JS6U06zRdL9x8jXP964WVIXzLSC7k1NsHOntTQ1WdZKtCKJvFZWjnMkQzrI5w6P16Q7e6oauAj4uIg8i1VG5GVVTWZE+EFgVtTnmfa6aG7AKr+Oqj4tIsVADXA0eiNVXQ2sBsvSSEIGIPFspr/sbuWyJVNH/dZprCDd4xIyOajMDwoqOtX4wIkeFtWV0zClbLQbqbQUli+3lii2b93Dxt9vZOi1JubseIplJx9kUvN+q6JwrDJpbLT2Y0gLWZXEkac4UhpjlBE5j+TKiDwHLBCROVjK4v3AX8Vssw+4DLhLRJYAxUCLE5nHY93mIwwODrG1uYOu3gGOdvYyuSR0SjaTYsUbci5WkAJ+qPgZLcOS+kpKQ0G2H+7iZHhwwtHJ25rbWf1KG1WzFlOxYDlNvQP8oifMTW9sZIn0jFglf/kL3HuvNfK9stJSHpFlzhzrtaYm6bL1htFkfRJHHuB0utcpwDVAL9YAv/tVNakqt6o6ICKfxCqCGATWqOoWEbkVeF5VHwY+C/y3iHwGKyj+EafusPHYcqidA609FIUClBcFOd4ltHT1MxB1qM7eAc6aNYn2HivDyQRDLfzQM4yVYU5tOdXlRQm5DceUf8tRlqxaaGVmvfGNIz8YGrIGJO7ZYy1NTbB+vfW+v3+0EpkzxyrwOH36KWnBXuEHq3A8sj2Jw+/X1w2cuqd+BTyOVdl2B3C+iOxU1SXj/2w09piLR2PWfSnq/VbgAocyJkxH7wAIFIes0E1tRRH7Wk/S3TcwKpsp3vze+Z4t4oeeYSoyJP3bQGA4HXjbnGXWs7DAehbe2lDMot4TlgLZvRt+9SurhMqhQ5Z1MmOGNUAx8hpZJk/OiIXiB6twIrI5Sy0brq8bOFUaFap6q4i8S1UvEpF3A2dM+CufUlVSQPvJfnrDgxQVBAgGhMmlIQIBiVu+PJcegFTxQ88wFRmc/jZeA3HnppNWA3FGzF9haAiOHRupyXXgAPz5z9brwYPWqPgZM0aWiDKZMcOydFwqRe8Hq3AisjmNNxuurxs4VRq99mufiJSo6loR+TzwpfF+5FeW1ldRGgpyuKOPjt4wlcUhzpw1icaaclNDZwwSCjxniFR6p05/m1QDEQjA1KnWEls1GHi16SBP/2kzfXv20Xj4BGcf28LUDRsshXL4sGWJRJRIrHJJwkrxg1WYCNlaGThbrm+qOFUat4tINXA/sEZEnsIq9ZGVWA3HSZbUV45qOK5YfupER4bUAs/pIJXeqdPfutVAbGtuZ/XGFqqmzKRiRiPP9A7wWHSK6eAgHD1qKZDI8qc/jbzv74e5c61lzpyR12nTThnI6AerMJfJl+vrdD6Ntfaq/7THV5wGvMtt4TJFNpvEXpBK4DldpNI7dfJbtxqICS2WYNByUdXXw8o4KfQdHVb8ZNcu6/XZZ633nZ2WAlm0CBYvhsWLuWJhLaufsbLasy1ekA1kczwmGdyaT+OnwHaXZcsoThqOfMiUiIcbvexsv3ZuNRApX8vKSjjjDGuJpqtrdJ2uBx5gyb59fGXqdLZU1rOzeiZTFy3mnFXnsDgLrns2PC/50vk082ng7IH0euSql38iJ3NTROP1tXMLN+5BqtcyKfr7LUXy6qsjy65dVjZYZNDj8uXWIMZgcOL9ZYhceV78jplPI0Gcpsl5mSnhdWpfqr3sXMkycSNgm1GXRmEhLF1qLVjP0WMvHaR/23aWtu7nvKeeo/bee63g+6JFsGyZpUSWLbPcYx4NXMyV5yVX8HQ+DT/g9IH0MlPCD3+iklCAZ3cfRxDOmlWVlMLKlyyTRPDKpTGq975sKc/3LuR3PWFu+uwcllQEYetW2LIF1q2D22+35jhZtmxEkSxdmrHaXIk8L9ngvsoVnCqNG4BfpjKfhl9w2oB5mSnhZaMb3dhcvqRuuGecDPmSZZIoXqSYjtvxWLUQzj3XWsBSGC0tsHmztaxZY7m2ampGXFrLllkzLbo0piSaiZ4Xry3vfMNp7akdIpLqfBq+wGkD5mWmhJeNrhtWTr5kmTglE73mpDoeItYYk0svHZmqd2jIiods2WIpkgcftOpyzZ8/WpHMnJmyW2ui58UPlnc+4dTSQFX7scZp3O+eOJnHaQPmZaaEl42uG1aO11kmfnZlZKrXnHLHIxAYmY/kqqusdT09sG2bpUSeeMKaorevb8SlFVmSdGtN9LwYd2dmcVqw8FLgA0AbsBmrNPpmVe1zUbaM4HUD5oR0yzxeo+qWlePVqF+/uzIy1WtOS8ejpOTUmRVbWkaskXvusWIlNTWjFUkCbq14z0t0VYLXjnSyfEblcFXqfHZ3phunKbd7gL8DQsDp9rJMVeenSc6EcWvmvonI1TTAic4r2887OsW1pbOXppZuWrv6qS4v5JYrl3p+Dp974CXqq4oJRLl0hlRpbu/l9ve6W97NE4traMgahBiJj2zeDPv3j3ZrLV9ulUkZx60V/Rz2hgd4bvcJFDhv7mTHM2p6iR+s33TP3PdHVb0oRRnTQqaURkbz6x3i5EFM5LzS9YBn4o8TaZSPd/Xxwr42igoCFAaF1pNhTp85yfOGJhueK9eJdmtFlgncWrHXqaWzly2HOggPKquW1vnK5RhNvGcc8EVHLN3jNDbYc1x8Kx3zW3jFr18+yA/+sIsDJ04SCgY4t3Eyn7psQdwb53c/qlM3TCLnlQ7X0kTyuqVQIu61ppZuigoCFIeC9IYHqbHLoHgdPM3LJIGx3FqbN1uurWi3lh1gHzhYQNXiRcOb11YUc+HCIprbe32rXMd6xktDgawK5DtVGkuxsqb+UUQ2YpUS2ZTkdK++4tcvH+TW/9tKT3iI4lCAgUFlw45jHOvq55arlp1y8/yeNurUN+7VeY0nL+BaHCLSKLd29TO5tIDe8CB9A0Msn1HpC6WfjTG2tFBbC5dcYi1wilvrHY8/TemPDtE5s5HjjQs41riAPdPmMGOmf5XrWM+4m9NIZwKnKbfvBhCREkYUyOtIbrpXX3H30/sYGLIGrRUEA4SCICLsOd4dt6H1e4/QqSXk1XmNJ6+bweFIo/zlh7dyvKuPmvKi4QBqe0/YF0o/W0uDp5VAYGS+9quuQj/azvce38a8Y/tpOLSLuuefYvHuu5hdHoRHzkgpW8stqzZ2P1ub21k8bbQs2TiNtFvTvf5cVe9ysJ8rgG9jTff6I1W9Lc421wBfwZru9SVVjZ1HPGW2Nbez/XAnPf0DFAaF0qICQsEARQVCV99A3IY2Ez3CVB5epxaDVz3d8eR12xW4pL6KW65cOsqP3N4TdlU5+iGwmcssqa/i+suXsG5zNb+buZAZb7qaK5bXUVbQPxIXiXVrRcaOLFwIoVDc/Y7nJgUSvqfx9rP/eA+loSCNNeXD22XjNNJOA+EbiJnuFUhqulcRCdq/XQUcAJ4DrrWneI1sswBrHMilqnpCRKaq6tHx9ptsIHxbcztfX7edv+w+Tk94iAAQDApVJSEGhyAYgGvPnZ1xP2mqWUrZluU0nrzrNh9JS3A4nQH9bLr2OU2S2VpjJSL0DwzSEx5K+J7G28/uli52HO3idXOnnLIPSFwhpYt0B8LdmO71XKBJVXcBiMh9wFXA1qhtPgZ8X1VPAEykMJzw06f3su/4SarLCmlu62UIGBxQ2rr7KSwIsnR6ZUKTMbndAKXqksk23/hE8qbDZZYuN5AZoewjYtxaAJw8aZVBiTMIcWZfFdMWL+VE4wL6yi1XUkVxAY9vO855c6YkfE/jWceza8o4GR6kqiQU9xnPlmfDy+leZwD7oz4fAM6L2WYhgIj8GcuF9RVVXRe7IxG5CbgJoKGhIQkR4MX9bZQXBSkuLKIwGOBQWw99g8qgwoULa8bMnoomHQPG3Bp5nS0PIowt73gKxY9uIL9n1uU9paVjDkKcsvb3VPz2QeoP7qa3vJLjjQvYP30uc4K1VM2fPGo3493Tsdyty6ZX+Ta7K1FSne7156R3utcCYAFwMTATK9X3NFVti95IVVcDq8FyTyVzAEGI/KCmopiaimJ6+gcYGIIffHBCSw1IT8/S79lZTkilgR9rRLAfR3fn4r3LeWpr4eKLqV90Fqs37GZSUZAZ7UcofW07lTtf5aZDf6D64W/TPaOB47Mj2VqNzGiYHXd3fk+USQWnSmOjqrYC30xhuteDwKyozzPtddEcAJ5V1TCwW0R2YCmR55yJfSpnzari6V2tiAhFBQH6Bobo6hvk/LnVCe/DzZ5ldGmEAyd6WFRXTsOUsqx/6NLRwCeqrDNtjSTSYPjRQjKMtmpfDdcy46IGzvrEBwH4zu+2M6/1AA2HdjHl5eeZ99C9zC0cgIdOHwmyL1sGNTVZ5x5OBqdK45fA2QCq+lMAEXldkvt4DlggInOwlMX7gdjMqAexZgX8iYjUYLmrdjmUOS4fPH82hzv6ONbVR0dvmKKCIHNqyvjg+fF7EPFwq2cZ3bAuqa+kNBRk++EuToYHWVpfldUPXTqssUTnWci0NTJRg+FXC8lgMZab9IbLFrFu8yR+Xz+PGZddaWVrFQ9ZGVqbN8PatXDLLdZgxWXLWLJ8OUuWL4cLFlsusRwhKaVhp7+eDVSIyBJgu6oO2V+vxqpBlRCqOiAinwQew4pXrFHVLSJyK/C8qj5sf/cmEdkKDAKfV9Xjycg8EUvqq/jcmxem1OtzyxSNbVjn1JZTbY9UznY/aDr8/Ikoa6+C0uPFk0ygPDsZ855ecIG1gDX3yIEDI6PZv/Mda4rdmTNHrJHly2HuXF9NqZsMyVoafwaKgRuBbwKLRKQNaAaS/ver6qPAozHrvhT1XoG/t5e0kWrA2C1TNJcDqOnw8yeirP14TdPhzjRuLp8gArNmWctb3mKtC4fhtdcsRfLii/Czn1mB90WLRiuSujrPptRNhqSUhqoeBO4RkZ2q+mcYHujXCLzqvnjZgxuZSrkcQE1HYDARZZ2Oa5pqQ50Od6Zxc/mYUGhkbvZrrrHWdXSMFGl89FH4+tet9dFjR5YsgYoK7+Qeg6QG94nI74BPq+oW+/OVWC6p9ar6bLqFTYRMVbmN4GZPz++DwlI9Vy96xW5c02i5C4PCkY4+ZlWXprQ/N+5zXlbETYKsssJU4fDhkblHtmyxxpLU1Y2em33BgjFHs6dKWkqji8h2VV1kv389sA64D7gA+FdV/VXKkqeI20pjvAcvHY28Xx90vyu08Ujlmsae94YdLXT2DnD+vOrhCX+cNNRu3OdMzr2RbWTz8zrM4CDs3DmiRDZvhoMHLcURUSIuTakL6RsR3hH1/sPAD1X1H0VkKvAw4LnScJOJzP90BDT9OiAvm4O3qVzT2PMODyrlRUGajnYPKw0n8YhU7/O25nb2tZ7kxX0nqCkvYv7UMmrKi3PGnZkq2fy8DhMMWnWyFi6Ed9kjGk6etNxaW7aMjGbv74fTTrOW669Pe1wkWaXRJCLvATYA78Qem6GqR0WkyG3hvGaiB8+PQdZ0kU/nGk3seZcXF9DXP0BHb3h4XaYb6khnZlpFER0nrUKLz+85weJpFQQCgawdy+MW25rbWb/1CEM6RFVJ4bBCzYnntbQUVqywlghHj47U1MpAID2Q5PafAf4aa1zFC6r6FICIhAD/RWxS5GBbDxXFo/Vq9IM3Y1IJnb0Do77P1Z5ePp1rNLHnPb+2jK6+QQqDAYZUh6vjJlKfzC0inZk5teWcPXsSlXZxzeaOvuxyv6SBiEINBYWiYIDe8CAb97ZxrKs3d5/XqVPh0kvhuusycriklIaqHlbVVUCRqr416qtLgCdclcwHjNVQFgataphbDrXzzK7j7DnW5VkDkimuWF43fH65fq7RxJ53YUGQhimlLJ9eSXN7L1UloYw31NGdmdqKYs6fO4W3nDaNhurSvFYYMKJQl02vpG/QitcWBoW/7G7lmZ3H2drczh3rd7Ctud1jSbOXZAPhiVYDbFPVjok3cx83A+Hxgml7j3cTEBnOntl7rJsdR7qYNaWEpfVVvglcpwO/BunTjR/OO1qGfa0nqa8sGjUvg8masohODmjp7KWppZuj7T209oS5ZGHtqJI8+W6VxZKuQPjd43yngNivdwH3JLlv3xFvHMD0qmJCBUFXRm1nWwqrX4P06cbr845NyOgPD/LCPqtmZy7UJXOT6DEwtRXF1FYU84ftR6kqLRxWslkZFPcRyQ7uuyRdgviV2Abjcw+8RHX52HGOREl1YJYZ2JV7jNUJiFdeBqwYRqggmFPF8FIl3iDSEyfDXDB/dAHSnAiKe0SygfC8x62AcHRDEBAZfr9u85GM/N7gLyKdgPae8KhOwLbm9rgJGbNrymioLuX2957BZ1YtNArDJuIdqCoJDcec3jh/CkUFo69fzgbFM0AiloaIyN8A24E/qOpgmmXyLdua22np7OXJpuNMLg2xdHoFRQUFjlwDqaaw5kMKrB9iCZlivPRuN8qO5NO1jPUORBQy5N7cFl4woaWhqgFV/QGwF/ioiPyNiLw9F8dljEfkwSssCPL6eZap++emVsIDg45cQqlaLLmeAjtezzsXGS+9O9XMNbeu5TY78+hzD7yUVRlI8ayP2P9stp6bFyQc01DVJqAJQERmAH8lIiXAUWCdqnalR0R/EN0TrCoJUVc50vtz0mNLtYBfLs8MBjkyojcJxrMmUq2i7Ma19CKG5qZ1NF4yg4kPJoejSZjsarc/AbAnR3qniFQC7VgKxNU5L/yA2+6gVBuCXJ4ZDPLD/RbNRJ2AVDK43LiWbirxRJRBJhvydHdQcs016HTmvmFU9ZiIvAK8G6se1QUi8qlci32ko8S2G/N4ZPPDNx65XCY+HunsBLhxLd1S4okqg0xamunsoOSiFeNYaYjIAqzJmM4DXgbWAl+JmskvkX1cAXwba+a+H6nqbWNs927gF8A5qpq5uudR5Lo7yG/k4/VOVyfAjWuZquKJ9LZ/u/UwhcEAy2dUEpDQmMogk5amW+cWz5LIRTdrKim3AaBVVS9W1U+r6h+TVBhB4PvAW4ClwLUisjTOdhXA3wKezteRSDDN4B7meruHG9cylWB8dCAeBVUdrgcF8ZVBJhM93Dq3eEkGE9Wvy0YcWxqqul1EvpnCsc8FmlR1F4CI3AdcBWyN2e6rwNeAz6dwLFfIZXeQHzHX+1Sc+se9nNI4urddURKiLzxIUYEMl5ePpwwyaWm6dW5wqiWRi27WlGIaqhqeeKsxmQHsj/p8AMvVNYyInA3MUtVfi8iYSkNEbgJuAmhoSLQ81sTkWgDLkN147R93qniiXU3za8t4YV8bRUGhvad/uFcfqwwynejhxrlFiLYkctHNmnIgPF2ISAD4JvCRibZV1dXAarAKFrpxfK//oAZDLNnqH4+tB3V2wyS2HOogIAGqSkJjKoNssDQnsiRyMcvRS6VxEJgV9XmmvS5CBbAc+INYE4tMAx4WkSszEQzP1j+oIXfxIg3ZDWs7trddWBBkbm15TnTAErEk3FJ+fvF8eFl76jlggYjMEZFC4P1YU8YCoKrtqlqjqo2q2gg8A2REYUBuBrAM2U2mqwC4NZI8l5MaMnVufqqQ4JmloaoDIvJJ4DGslNs1qrpFRG4FnlfVh8ffQ3rJxQCWIbvJtH/cTWs7G1xNTsnEufnJ8+FpTENVHwUejVn3pTG2vTgTMkXIxQBWJvCLCZ2LZNo/nm+j8v2Mn+6FbwPhXpOLAax0Y5IHxsYtZZrJHruxtv2Dn+6FURrj4KVJnY09dj+Z0H4iW5Wpsbb9g5/uhZmEyYf4KeiVDCZ5ID7ZOmFWLgewsw0/3QtjafiQbO2x+8mE9hN+8kcnSy4HsL0mWW+CX+6FURo+JFsbGT+Z0H4iW5RpNrpEs5VUXZZe3ivjnvIh2TorXzwT+vIltazbfCSvZ0RLdea9TJCtLtFsJRWXpdf3ylgaPsSLHns6snuyNQDsNtmQiZetLtFsJRVvgtf3yigNH5LpRiZdjbvXD7ef8Is/eiyy1SWaraTisvT6Xhml4VMy2cikq3H3+uE2JE5sI9bS2cuWQx2EB5U71u8w8Q2XScWb4HWMzMQ0XGBbczt3rN+RtX77dKXKZmtsJh+Jjrsc6ejh2V2tdPYOcMasShPfSAOppNB6HSMzlkaKZKvfPjqGsa/1JOGBQRpryoe/d6NxN9lU2UO0S/TZ3ccpLy5g+YxKaspHLMV8dCumE6feBK9jZEZppEg2+u1jFV1/eJAX9rUB0DClzLXG3euH25AckUYs4lYMWFMSAMat6De8jJEZpZEi2ei3j1V0c2otC6O5o49QQdCVxj02G+uGNzRm5CE3Yw1Sx2ufucHfmJhGimSj3z5eDGN2TRkN1aXc/t4z+MyqhSkrDC/yyL3OX88VvPaZG/yNUbSy/HsAAAnBSURBVBopko1/sHQrOq9qLWVrjSe/4ac6Rwb/YdxTKTKR3z4Zd0mmXCvpDlB75bLLRlehX/H7uBKDd3iqNETkCuDbWDP3/UhVb4v5/u+BG4EBoAX4qKruTYcsqTTYY/3BksmsymQWVroD1F75xI0v3mBIP54pDREJAt8HVgEHgOdE5GFV3Rq12YvASlU9KSIfB74OvM9tWfwwIjrTWVjp7El6lWprUnwN+Uimkz+8jGmcCzSp6i5V7QfuA66K3kBVf6+qJ+2PzwBp+fenyxeezKC5XJqLwiufuPHFG/INL5I/vHRPzQD2R30+AJw3zvY3AL+J94WI3ATcBNDQ0JC0IIn6wpPV6Mm4S3LNteKVT9z44g25xERtjhfjxLIie0pEPgisBL4R73tVXa2qK1V1ZW1tbdL7TySbyIlGTyazKhuzsAwGQ/pIpM3xwkPhpdI4CMyK+jzTXjcKEbkc+BfgSlXtS4cgiTTYTlxYybhLjGvFkM9ke/22dJBIm+PFODEv3VPPAQtEZA6Wsng/8FfRG4jIWcB/AVeo6tF0CZJINpHTdM5k3CXGtWLIR7K1flu6SaTN8SL5wzOloaoDIvJJ4DGslNs1qrpFRG4FnlfVh7HcUeXAA2LVwdmnqlemQ56JGuxcizkYDH4hG+u3ZYJE2hwv6rt5Ok5DVR8FHo1Z96Wo95dnXKgxMOmcBkN6MIMy45Nom5NpD0VWBML9gIk5GAzpIRvrt2UCv7Y5poxIEpiYg8HgPsaKHxs/tjnG0jAYDJ7i1x61IT7G0jAYDJ7jxx61IT7G0jAYDAZDwhilYTAYDIaEMUrDYDAYDAljlIbBYDAYEsYoDYPBYDAkjFEaBoPBYEgYozQMBoPBkDCiql7L4Coi0gI4nUe8BjjmojjZQL6dc76dL5hzzhdSPefZqjrhhEQ5pzRSQUSeV9WVXsuRSfLtnPPtfMGcc76QqXM27imDwWAwJIxRGgaDwWBIGKM0RrPaawE8IN/OOd/OF8w55wsZOWcT0zAYDAZDwhhLw2AwGAwJY5SGwWAwGBLGKA1ARK4Qke0i0iQiX/BaHrcQkVki8nsR2SoiW0Tkb+311SKyXkRes18n2+tFRL5jX4eXReRsb8/AOSISFJEXReQR+/McEXnWPrefi0ihvb7I/txkf9/opdxOEZFJIvILEXlVRLaJyPm5fJ9F5DP2M71ZRO4VkeJcu8ciskZEjorI5qh1Sd9TEbnO3v41EbkuVbnyXmmISBD4PvAWYClwrYgs9VYq1xgAPquqS4HXAZ+wz+0LwO9UdQHwO/szWNdggb3cBPww8yK7xt8C26I+fw24Q1XnAyeAG+z1NwAn7PV32NtlI98G1qnqYuAMrHPPyfssIjOATwMrVXU5EATeT+7d47uAK2LWJXVPRaQa+DJwHnAu8OWIonGMqub1ApwPPBb1+Z+Af/JarjSd60PAKmA7UG+vqwe22+//C7g2avvh7bJpAWbaf6hLgUcAwRopWxB7z4HHgPPt9wX2duL1OSR5vlXA7li5c/U+AzOA/UC1fc8eAd6ci/cYaAQ2O72nwLXAf0WtH7WdkyXvLQ1GHsAIB+x1OYVtkp8FPAvUqWqz/dVhoM5+nyvX4lvAPwBD9ucpQJuqDtifo89r+Jzt79vt7bOJOUAL8BPbJfcjESkjR++zqh4Ebgf2Ac1Y92wjuX2PIyR7T12/10Zp5AEiUg6sBf5OVTuiv1Or+5Ezedci8nbgqKpu9FqWDFIAnA38UFXPAroZcVsAuXWfbffKVVjKcjpQxqlunJzHq3tqlAYcBGZFfZ5pr8sJRCSEpTD+R1V/aa8+IiL19vf1wFF7fS5ciwuAK0VkD3Aflovq28AkESmwt4k+r+Fztr+vAo5nUmAXOAAcUNVn7c+/wFIiuXqfLwd2q2qLqoaBX2Ld91y+xxGSvaeu32ujNOA5YIGdeVGIFVB72GOZXEFEBPgxsE1Vvxn11cNAJIviOqxYR2T9h+1MjNcB7VGmcFagqv+kqjNVtRHrXj6hqh8Afg+8x94s9pwj1+I99vZZ1SNX1cPAfhFZZK+6DNhK7t7nfcDrRKTUfsYj55uz9ziKZO/pY8CbRGSybaG9yV7nHK8DPX5YgLcCO4CdwL94LY+L5/UGLPP1ZWCTvbwVy5/7O+A14HGg2t5esDLJdgKvYGWneH4eKZz/xcAj9vu5wF+AJuABoMheX2x/brK/n+u13A7P9UzgeftePwhMzuX7DNwCvApsBn4KFOXaPQbuxYrZhLGsyRuc3FPgo/a5NwHXpyqXKSNiMBgMhoQx7imDwWAwJIxRGgaDwWBIGKM0DAaDwZAwRmkYDAaDIWGM0jAYDAZDwhilYcgrRGRQRDZFLY0islJEvmN/f7GIvD5q+3c6KWApIl0uyevKfgwGtyiYeBODIafoUdUzY9btwRrjANbYji7gKfvzO7EK4m3NhHAGg98xloYh77Gti0fsoo43A5+xrZCLgCuBb9if59nLOhHZKCJ/EpHF9j7miMjTIvKKiPzbGMe5TUQ+EfX5KyLyOREpF5HficgL9u+vGkvGqM/fE5GP2O9XiMgfbZkeiyoz8Wmx5lJ5WUTuc+2CGfIaY2kY8o0SEdlkv9+tqldHvlDVPSJyJ9ClqrcDiMjDWKPKf2F//h1ws6q+JiLnAT9gpL7VD1X1nmjFEMPPsSrwft/+fA1WSe9e4GpV7RCRGuAZEXlYExh5a9cW+y5wlaq2iMj7gH/HGgX8BWCOqvaJyKREL5DBMB5GaRjyjXjuqYSwqwW/HnjAKnkEWOUrwCqY9277/U+JM9GPqr4oIlNFZDpQizUx0H674f8PEbkQq5z7DKyS14cTEGsRsBxYb8sUxCo9AVZJkf8RkQexSosYDCljlIbBkDgBrDkbxlI6idTkeQCraN40LMsD4ANYSmSFqobtCr3FMb8bYLQ7OfK9AFtU9fw4x3obcCHwDuBfROQ0HZlvwmBwhIlpGAyj6QQq4n1Way6S3SLyXhiel/kMe7s/Y1XVBUsJjMXP7e3eg6VAwCrVfdRWGJcAs+P8bi+wVKz5ridhVXYFa4a2WhE535YpJCLLRCQAzFLV3wP/aB+jPKErYDCMg1EaBsNo/g+42g58vxFrTo7PizUj3jwshXCDiLwEbMGaDAisOck/ISKvMM7MaKq6BUsJHdSRcuT/A6y0f/thrOqtsb/bD9yPVdX1fuBFe30/lgL6mi3TJiwXWhD4mb3PF4HvqGqb04tiMEQwVW4NBoPBkDDG0jAYDAZDwhilYTAYDIaEMUrDYDAYDAljlIbBYDAYEsYoDYPBYDAkjFEaBoPBYEgYozQMBoPBkDD/H9II6hJ3sxPxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# annotations\n",
    "abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
    "abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "\n",
    "\n",
    "plot_lm_3 = plt.figure()\n",
    "plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5);\n",
    "sns.regplot(model_fitted_y, model_norm_residuals_abs_sqrt,\n",
    "          scatter=False,\n",
    "          ci=False,\n",
    "          lowess=True,\n",
    "          line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8});\n",
    "plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$');\n",
    "\n",
    "# annotations\n",
    "abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)\n",
    "abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "for i in abs_norm_resid_top_3:\n",
    "    plot_lm_3.axes[0].annotate(i,\n",
    "                             xy=(model_fitted_y[i],\n",
    "                                 model_norm_residuals_abs_sqrt[i]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more horizontal the red line is, the more likely the data is homoscedastic. Heteroscedasticity typically has a sideways “V” shape.\n",
    "\n",
    "There are also some more formal tests you can run:\n",
    " - **Breush-Pagan test** -  tests whether the variance of the errors from a regression is dependent on the values of the independent variables. In that case, heteroskedasticity is present. If the test statistic has a p-value below an appropriate threshold (e.g. p < 0.05) then the null hypothesis of homoskedasticity is rejected and heteroskedasticity assumed.\n",
    " - **Goldfeld-Quandt test** - tests whether the variances of the errors of the regression model are not constant, but instead monotonically related to a pre-identified explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lagrange multiplier statistic', 4.406698315033664)\n",
      "('p-value', 0.11043268186997897)\n",
      "('f-value', 2.219195546532248)\n",
      "('f p-value', 0.11140693859000016)\n"
     ]
    }
   ],
   "source": [
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(results.resid, results.model.exog)\n",
    "for i in list(zip(name, test)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F statistic', 0.7240923028749447)\n",
      "('p-value', 0.9432070241790471)\n"
     ]
    }
   ],
   "source": [
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(results.resid, results.model.exog)\n",
    "for i in list(zip(name, test)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we don't see much evidence for heteroscedasticity above, the two most common methods of “fixing” heteroscedasticity is using a weighted least squares approach, or using a heteroscedastic-corrected covariance matrix (hccm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. No perfect multicolinearity\n",
    "Two variables are perfectly colinear if one can be determined perfectly by the other. For example, $a$ and $b$ below are perfectly colinear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = a + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to fit a model using both of these variables, our estimate for either $\\beta$ would be meaningless. $\\beta_a$, for example, is the change in the dependent variable associated with a one unit change in $a$ *holding $b$ constant*. But if you hold $b$ constant, then $a$ doesn't change because they are perfectly colinear. Although the OLS will output an estimate for $\\beta_a$, it is in fact undefined. The solution in such a situation is to drop one of the colinear variables.\n",
    "\n",
    "#### A more formal definition\n",
    "The regressors in $X$ must all be [linearly independent](https://en.wikipedia.org/wiki/Linear_independence). Mathematically, this means that the matrix X must have full [column rank](https://en.wikipedia.org/wiki/Rank_(linear_algebra)#Main_definitions) almost surely: $\\Pr\\!\\big[\\,\\operatorname{rank}(X) = p\\,\\big] = 1$. Usually, it is also assumed that the regressors have finite moments up to at least the second moment. Then the matrix $Q_{xx} = E[X^TX/n]$ is finite and positive semi-definite. When this assumption is violated the regressors are called linearly dependent or perfectly multicollinear. In such case the value of the regression coefficient $\\beta$ cannot be learned, although prediction of $y$ values is still possible for new values of the regressors that lie in the same linearly dependent subspace.\n",
    "\n",
    "#### The effect of multicollinearity\n",
    "Severe multicollinearity is a problem because it can increase the variance of the coefficient estimates and make the estimates very sensitive to minor changes in the model. The result is that the coefficient estimates are unstable and difficult to interpret. Multicollinearity saps the statistical power of the analysis, can cause the coefficients to switch signs, and makes it more difficult to specify the correct model.\n",
    "\n",
    "In our OLS equation, the product $N=X^{T}X$ is a [normal matrix](https://en.wikipedia.org/wiki/Normal_matrix) and its inverse, $Q=N^{–1}$, is the cofactor matrix of $\\beta$, which is closely related to its covariance matrix, $C_\\beta$. Together, the matrix $(X^{T}X)^{–1}X^T = QX^{T}$ is called the [Moore–Penrose pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) matrix of $X$. This formulation highlights the point that estimation can be carried out if, and only if, there is no perfect multicollinearity between the explanatory variables (which would cause the normal matrix to have no inverse).\n",
    "\n",
    "To see how the presence of multicollinearity pans out, we'll try to calculate $Q$ after adding a linearly dependent column to our design matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the normal matrix with the data as-is\n",
    "normal_matrix = np.dot(X_T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we were to introduce a new column vector into our matrix $X$ that is perfectly colinear with another column vector in $X$, we'll see that we can no logner calculate the inverse of the $X^{T}X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967944</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967944</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3\n",
       "0 NaN       NaN       NaN       NaN\n",
       "1 NaN  1.000000  0.967944  1.000000\n",
       "2 NaN  0.967944  1.000000  0.967944\n",
       "3 NaN  1.000000  0.967944  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a linearly dependent column to X\n",
    "X_colinear = np.column_stack((X, X[:,1] + 2))\n",
    "#calculate correlation matrix to show perfect correlation between columns 1 and 3\n",
    "pd.DataFrame(X_colinear).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_colinear_T = np.transpose(X_colinear)\n",
    "normal_matrix_colinear = np.dot(X_colinear_T, X_colinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_matrix_test(X):\n",
    "    '''\n",
    "    Numpy will invert singular matrices containing floating points due to rounding errors, so we'll\n",
    "    test if the condition of the matrix (the ratio of the largest singular value of that matrix \n",
    "    to the smallest singular value) is less than 1/np.finfo(X.dtype).eps, where the denominator is \n",
    "    has the precision of the array's dtype, which may differ from sys.float_info.epsilon.\n",
    "    \n",
    "    '''\n",
    "    if np.linalg.cond(X) < 1/np.finfo(X.dtype).eps:\n",
    "        i = np.linalg.inv(X)\n",
    "    else:\n",
    "        print(\"likely singular\")\n",
    "        return\n",
    "        \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.41118664e-02, -1.76003399e-02,  1.46301906e-03],\n",
       "       [-1.76003399e-02,  9.41647814e-03, -8.82244829e-04],\n",
       "       [ 1.46301906e-03, -8.82244829e-04,  8.82244829e-05]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singular_matrix_test(normal_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likely singular\n"
     ]
    }
   ],
   "source": [
    "singular_matrix_test(normal_matrix_colinear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of floating point precision, we can still calculate $Q$ and create an OLS model. To see why we shouldn't do that, we'll run 1,000 trials where we keep creating OLS models where one random observation has been dropped until the parameters we get are within 1% of the values we found when including all observations. This will demonstrate how how singular (and nearly singular) matrices can unbpredictably influence the regression coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1000 trials, OLS parameter conversion occurred after an average of 40.938 iterations.\n"
     ]
    }
   ],
   "source": [
    "def compute_ci(data, confidence = 0.95):\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = sem(data)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    \n",
    "    return start, end\n",
    "\n",
    "\n",
    "\n",
    "def fit_random_ols_models_until_conversion(X, y, params, n_drop = 1, alpha = .01, n_iter = 1000):\n",
    "    \n",
    "    counters = []\n",
    "    for i in range(n_iter):\n",
    "        #fit OLS on orginal colinear data\n",
    "        ols = sm.OLS(y, X).fit()\n",
    "        params = ols.params\n",
    "\n",
    "        params_list = []\n",
    "        converged = False\n",
    "        counter = 0\n",
    "        while not converged:\n",
    "            counter += 1\n",
    "            rows_to_drop = np.random.choice(y.shape[0], y.shape[0]-n_drop, replace=True)\n",
    "            #randomly drop n_drop rows from y\n",
    "            _y = y[rows_to_drop]\n",
    "            #randomly drop n_drop rows from X\n",
    "            _X = X[rows_to_drop, :]\n",
    "            _ols = sm.OLS(_y, _X).fit()\n",
    "            _params = _ols.params\n",
    "            params_list.append(_params)\n",
    "            param_df = pd.DataFrame(params_list)\n",
    "            is_converged = []\n",
    "            for i, param in enumerate(params):\n",
    "                if i == 0:\n",
    "                    #this is the intercept\n",
    "                    continue\n",
    "                random_params_mean = param_df[i].mean()\n",
    "                percent_diff = np.abs(param-random_params_mean) / param\n",
    "                if percent_diff < alpha:\n",
    "                    is_converged.append(True)\n",
    "                else:\n",
    "                    is_converged.append(False)\n",
    "            converged = True if all(is_converged) else False\n",
    "        counters.append(counter)\n",
    "    mean_counter = np.mean(counters)\n",
    "    print(f\"After {n_iter} trials, OLS parameter conversion occurred after an average of {mean_counter} iterations.\")\n",
    "\n",
    "fit_random_ols_models_until_conversion(X_colinear, y, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expirment above was designed to show how susceptible parameter estimation is to multicolinearity.\n",
    "\n",
    "Even so, near multicollinearity isn't necessarily a problem. The more important thing to **focus on is the standard errors of the coefficients of the variables you suspect of being involved in the multicollinearity.** If those standard errors are small enough to give you the degree of precision in coefficient estimates that you need for the purposes of your analysis, then there is nothing more to say. If they don't, then you have a problem, but one that you cannot solve short of getting an entirely different data set! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Multicolinearity\n",
    "\n",
    "There are two common measures of multicolinearity:  the **variance inflation factor (VIF)** and the **condition number**\n",
    "\n",
    "#### Variance Inflation Factor\n",
    "The variance inflation factor is the ratio of variance in a model with multiple terms, divided by the variance of a model with one term alone. It quantifies the severity of multicollinearity in an ordinary least squares regression analysis. It provides an index that measures how much the variance (the square of the estimate's standard deviation) of an estimated regression coefficient is increased because of collinearity.\n",
    "\n",
    "We can calculate the VIF for each of our regressors like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.851860186018582, 15.85186018601861]\n"
     ]
    }
   ],
   "source": [
    "#note that variance_inflation_factor expects the presence of a constant in the matrix of explanatory variables\n",
    "vif = [variance_inflation_factor(X, i) for i in range(1, X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf, 15.85186018601861]\n"
     ]
    }
   ],
   "source": [
    "#and with the perfectly colinear data, which will return infinity!\n",
    "vif = [variance_inflation_factor(X_colinear, i) for i in range(1, X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, a VIF of $15$ means that the variance (a measure of imprecision) of the estimated coefficient is $15$ times higher because of correlation between the two independent variables. \n",
    "\n",
    "\n",
    "#### When is multicollinearity a problem?\n",
    "Testing for the signs of multicollinearity becomes important when you want to interpet the impact of a single independent variable by looking at its coefficient $\\beta$. When we test whether a coefficient $\\beta_i$ is significant, we're performing a statistical hypothesis test\n",
    "\n",
    "$$\n",
    "𝐻_0:\\beta_𝑖=0$ versus $𝐻_1:\\beta_𝑖≠0\n",
    "$$\n",
    "\n",
    "If $𝐻_0$ is true, then the estimator $\\hat{\\beta}_i$ follows a normal distribution with mean $0$, i.e. if $𝐻_0$ is true then $\\hat{\\beta}_i \\sim N(0;\\sigma_{\\hat{\\beta}_i})$.\n",
    "\n",
    "The value for $\\beta_i$ that we compute from our sample comes from this distribution, therefore $\\frac{|\\bar{\\beta}_i - 0|}{\\sigma_{\\hat{\\beta}_i}}$ is an outcome of a standard normal random variable. So for a significance level $\\alpha$ we will reject the $𝐻_0$ whenever $\\frac{|\\bar{\\beta}_i | }{\\sigma_{\\hat{\\beta}_i}} \\ge z_{\\frac{\\alpha}{2}}$\n",
    "\n",
    "If there is correlation between your independent variables $𝑥_1$ and $𝑥_2$ then it can be shown that $\\sigma_{\\hat{\\beta}_i}$ will be larger than when $𝑥_1$ and $𝑥_2$ are uncorrelated. That's because $x_1$ and $x_2$ 'move together' when they are strongly correlated. What linear regression tries to do is to 'assign' a change in the dependent variable $𝑦$ to either $𝑥_1$ or $𝑥_2$. Obviously, if both 'move together' (because of high correlation) then it will be difficult to 'decide' which of the $𝑥$'s is 'responsible' for the change in $𝑦$ (because they both change). Therefore the estimates of the $𝛽_𝑖$ coefficients will be less precise. Therefore, if $𝑥_1$ and $𝑥_2$ are correlated, the null hypothesis will be 'more difficult to reject' because of the higher denominator.\n",
    "\n",
    "The Variance Inflating Factor (VIF) tells you how much higher the variance $\\sigma_{\\hat{\\beta}_i}$ are when $𝑥_1$ and $𝑥_2$ are correlated compared to when they are uncorrelated. \n",
    "\n",
    "\n",
    "All of this isn't a problem if your goal is to make predictions, as the precision/accuracy of those won't be affected. But if you want to analyse the impact of a single independent variable, then there may be a problem because the estimates of the coefficients are imprecise (i.e. if you would estimate them with another sample then they may change a lot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition Number\n",
    "\n",
    "The condition number associated with the linear equation $Ax = b$ gives a bound on how inaccurate the solution $x$ will be after approximation. Note that this is before the effects of round-off error are taken into account; conditioning is a property of the matrix, not the algorithm or floating point accuracy of the computer used to solve the corresponding system. \n",
    "\n",
    "Very roughly, the condition number is the rate at which the solution, $x$, will change with respect to a change in $b$. Thus, if the condition number is large, even a small error in $b$ may cause a large error in $x$. On the other hand, if the condition number is small then the error in $x$ will not be much bigger than the error in $b$.\n",
    "More precisely, the condition number is the maximum ratio of the relative error in x to the relative error in b. We used it above in comparison with our machine's floating point precision to determine that our perfeclty colinear matrix was in fact singular. \n",
    "\n",
    "As a rule of thumb, if the condition number $\\kappa(A) = 10^k$, then you may lose up to $k$ digits of accuracy on top of what would be lost to the numerical method due to loss of precision from arithmetic methods. However, the condition number does not give the exact value of the maximum inaccuracy that may occur in the algorithm. It generally just bounds it with an estimate (whose computed value depends on the choice of the norm to measure the inaccuracy).\n",
    "\n",
    "If we use `statsmodels` to run an OLS with data that has multicolinearity issues, it'll let you know by adding an error about either the conidtion number being to high or the smallest eigenvalue being too small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>8.067e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Apr 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:03:45</td>     <th>  Log-Likelihood:    </th> <td> -293.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   592.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   602.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2351</td> <td>    0.105</td> <td>    2.242</td> <td> 0.026</td> <td>    0.028</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1380</td> <td>    0.154</td> <td>   -0.897</td> <td> 0.371</td> <td>   -0.441</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    9.9890</td> <td>    0.010</td> <td> 1006.994</td> <td> 0.000</td> <td>    9.969</td> <td>   10.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3323</td> <td>    0.060</td> <td>    5.556</td> <td> 0.000</td> <td>    0.214</td> <td>    0.450</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.456</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.796</td> <th>  Jarque-Bera (JB):  </th> <td>   0.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.112</td> <th>  Prob(JB):          </th> <td>   0.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.894</td> <th>  Cond. No.          </th> <td>5.05e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.64e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 8.067e+06\n",
       "Date:                Fri, 19 Apr 2019   Prob (F-statistic):               0.00\n",
       "Time:                        08:03:45   Log-Likelihood:                -293.19\n",
       "No. Observations:                 200   AIC:                             592.4\n",
       "Df Residuals:                     197   BIC:                             602.3\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2351      0.105      2.242      0.026       0.028       0.442\n",
       "x1            -0.1380      0.154     -0.897      0.371      -0.441       0.165\n",
       "x2             9.9890      0.010   1006.994      0.000       9.969      10.009\n",
       "x3             0.3323      0.060      5.556      0.000       0.214       0.450\n",
       "==============================================================================\n",
       "Omnibus:                        0.456   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.796   Jarque-Bera (JB):                0.514\n",
       "Skew:                          -0.112   Prob(JB):                        0.774\n",
       "Kurtosis:                       2.894   Cond. No.                     5.05e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.64e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_ols = sm.OLS(y, X_colinear).fit()\n",
    "col_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Normality\n",
    "It is sometimes additionally assumed that the errors have normal distribution conditional on the regressors: $$\\varepsilon \\mid X\\sim \\mathcal{N}(0, \\sigma^2I_n)$$ This assumption is not needed for the validity of the OLS method, although certain additional finite-sample properties can be established in case when it does (especially in the area of hypotheses testing). Also when the errors are normal, the OLS estimator is equivalent to the maximum likelihood estimator (MLE), and therefore it is asymptotically efficient in the class of all regular estimators. Importantly, the normality assumption applies only to the error terms; contrary to a popular misconception, the response (dependent) variable is not required to be normally distributed.\n",
    "\n",
    "We can visually inspect this assumption with a Q-Q Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "QQ = ProbPlot(model_norm_residuals)\n",
    "plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
    "plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "plot_lm_2.axes[0].set_ylabel('Standardized Residuals');\n",
    "# annotations\n",
    "abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
    "abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "for r, i in enumerate(abs_norm_resid_top_3):\n",
    "    plot_lm_2.axes[0].annotate(i,\n",
    "                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],\n",
    "                                   model_norm_residuals[i]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good normal QQ plot has all of the residuals lying on or close to the red line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Properties\n",
    "When assumptions 1-6 are satisfied, we can say that our OLS model has the following properties:\n",
    "\n",
    "1. **Linear** - OLS estimators are linear functions of the values of $Y$ (the dependent variable) which are linearly combined using weights that are a non-linear function of the values of $X$ (the regressors or explanatory variables). So the OLS estimator is a \"linear\" estimator with respect to how it uses the values of the dependent variable only, and irrespective of how it uses the values of the regressors.\n",
    "2. **Unbiased** - Suppose that the *population* size is $100$. We use samples of size $10$ to estimate the $\\alpha$  and $\\beta$ of the population. Everytime we use a different sample (a different set of $10$ unique parts of the population), we will get a different $\\alpha$ and $\\beta$. If our assumptions are met, the mean parameter values of repeated resampling and OLS estimations will give you the population values for $\\alpha$ and $\\beta$. That is, $\\operatorname{E}(\\hat{\\boldsymbol{\\beta}}) = (\\beta)$.\n",
    "3. **Efficient** - This means OLS has the minimum variance of all other approaches. (Variance is a measure of how far the different $\\alpha$ and $\\beta$ are from their true population mean.)\n",
    " - An estimator that is unbiased but does not have the minimum variance is not good.\n",
    " - An estimator that has the minimum variance but is biased is not good\n",
    " - An estimator that is unbiased and has the minimum variance of all other estimators is the best (efficient).\n",
    "4. **Consistent** - A consistent estimator is one which approaches the real value of the parameter in the population as the size of the sample, $n$, increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers, Influence and Leverage\n",
    "All of the OLS assumptions can be met, but you may still end up with a error-laden model if your sample data contains problematic points:\n",
    "\n",
    " - **Outliers**: an outlier is defined as an observation that has a large residual. In other words, the observed value for the point is very different from that predicted by the regression model.\n",
    " - **Leverage points**: A leverage point is defined as an observation that has a value of x that is far away from the mean of x. \n",
    " - **Influential observations**: An influential observation is defined as an observation that changes the slope of the line. Thus, influential points have a large influence on the fit of the model. One method to find influential points is to compare the fit of the model with and without each observation.\n",
    "\n",
    "\n",
    "### Leverage\n",
    "The matrix formulation of our OLS regression can be written as:\n",
    "\n",
    "$$\n",
    "Y=X\\beta+\\epsilon\n",
    "$$\n",
    "\n",
    "Therefore, the predicted responses can be represented in matrix notation as:\n",
    "\n",
    "$$\n",
    "\\hat{y}=Xb\n",
    "$$\n",
    "\n",
    "And the estimated coefficients are represented in matrix notation as:\n",
    "\n",
    "$$\n",
    "b = (X^{'}X)^{-1}X^{'}y\n",
    "$$\n",
    "\n",
    "Thus the predicted responses can be alternatively written as:\n",
    "\n",
    "$$\n",
    "\\hat{y}=X(X^{'}X)^{-1}X^{'}y\n",
    "$$\n",
    "\n",
    "That is, the predicted responses can be obtained by pre-multiplying the $n × 1$ column vector, $y$, containing the observed responses by the $n × n$ matrix $H$:\n",
    "\n",
    "$$\n",
    "H=X(X^{'}X)^{-1}X^{'}\n",
    "$$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$\n",
    "\\hat{y}=Hy\n",
    "$$\n",
    "\n",
    "Again, statisticians often call this $n × n$ matrix $H$ \"the hat matrix\" because it's the matrix that puts the hat ($ˆ$) on the observed response vector $y$ to get the predicted response vector $\\hat{y}$. **This is important for calculating leverage because $H$ contains the \"leverages\" that help us identify extreme $x$ values.**\n",
    "\n",
    "If we actually perform the matrix multiplication on the right side of this equation:\n",
    "\n",
    "$$\n",
    "\\hat{y}=Hy\n",
    "$$\n",
    "\n",
    "we can see that the predicted response for observation $i$ can be written as a linear combination of the $n$ observed responses $y_1$, $y_2$, ..., $y_n$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i=h_{i1}y_1+h_{i2}y_2+...+h_{ii}y_i+ ... + h_{in}y_n  \\;\\;\\;\\;\\; \\text{ for } i=1, ..., n\n",
    "$$\n",
    "\n",
    "Above, the weights $h_{i1}, h_{i2}, ..., h_{ii}, ..., h_{in}$ depend only on the predictor values. That is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_1=h_{11}y_1+h_{12}y_2+\\cdots+h_{1n}y_n\n",
    "$$\n",
    "$$\n",
    "\\hat{y}_2=h_{21}y_1+h_{22}y_2+\\cdots+h_{2n}y_n\n",
    "$$\n",
    "<br>\n",
    "$$\n",
    "\\hat{y}_n=h_{n1}y_1+h_{n2}y_2+\\cdots+h_{nn}y_n\n",
    "$$\n",
    "\n",
    "Because the predicted response can be written as:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i=h_{i1}y_1+h_{i2}y_2+...+h_{ii}y_i+ ... + h_{in}y_n  \\;\\;\\;\\;\\; \\text{ for } i=1, ..., n\n",
    "$$\n",
    "\n",
    "the leverage, $h_{ii}$, quantifies the influence that the observed response $y_i$ has on its predicted value $\\hat{y_i}$. That is, if ${h_ii}$ is small, then the observed response $y_i$ plays only a small role in the value of the predicted response $\\hat{y_i}$. On the other hand, if $h_{ii}$ is large, then the observed response $y_i$ plays a large role in the value of the predicted response $\\hat{y_i}$. It's for this reason that the hii are called the \"leverages.\"\n",
    "\n",
    "How do we know when a leverage value is too large? A common rule is to flag any observation whose leverage value, $h_{ii}$, is more than $3$ times larger than the mean leverage value:\n",
    "\n",
    "$$\n",
    "\\bar{h}=\\frac{\\sum_{i=1}^{n}h_{ii}}{n}=\\frac{p}{n}\n",
    "$$\n",
    "\n",
    "That is, if:\n",
    "\n",
    "$$\n",
    "h_{ii} >3\\left( \\frac{p}{n}\\right)\n",
    "$$\n",
    "\n",
    "Then we should flag the observation as a leverage point.\n",
    "\n",
    "We'll work this out with some toy data that actually contains a leverage point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlessmcallister/.local/share/virtualenvs/learning-data-science-Oygx0A85/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x120465390>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('assets/leverage.txt',\n",
    "                 delim_whitespace=True, \n",
    "                 names=('Row', 'x', 'y')).iloc[1:]\n",
    "df = df.astype(float)\n",
    "df = sm.add_constant(df)\n",
    "plt.scatter(df['x'], df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our levarage point way off to the right there $(x = 18, y = 20)$. \n",
    "There are $n = 21$ data points and $p = 2$ parameters (with intercept $\\beta_0$ and slope $\\beta_1$). Therefore:\n",
    "\n",
    "$$\n",
    "3\\left( \\frac{p}{n}\\right)=3\\left( \\frac{2}{21}\\right)=0.286\n",
    "$$\n",
    "\n",
    "Any observation with a leverage greater than $0.286$ would be a leverage point. In order to calculate our leverage, let's fit a model and then access that method on the OLS object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20]),)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_model = sm.OLS(df['y'], df[['const', 'x']]).fit()\n",
    "# we can get the leverage for each observation like this\n",
    "model_leverage = lev_model.get_influence().hat_matrix_diag\n",
    "np.where(model_leverage > 0.286)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Ordinary residuals are defined for each observation, $i = 1, ..., n$ as the difference between the observed and predicted responses:\n",
    "\n",
    "$$\n",
    "e_i=y_i-\\hat{y}_i\n",
    "$$\n",
    "\n",
    "A major problem with interpreting residuals is that their magnitude depends on the units of measurement, thereby making it difficult to use the residuals as a way of detecting unusual $y$ values. We can eliminate the units of measurement by dividing the residuals by an estimate of their standard deviation, thereby obtaining what are known as **studentized residuals** (also called internally studentized residuals).\n",
    "\n",
    "#### Studentized residuals (or internally studentized residuals)\n",
    "Studentized residuals (or internally studentized residuals) are defined for each observation, $i = 1, ..., n$ as an ordinary residual divided by an estimate of its standard deviation:\n",
    "\n",
    "$$\n",
    "r_{i}=\\frac{e_{i}}{s(e_{i})}=\\frac{e_{i}}{\\sqrt{MSE(1-h_{ii})}}\n",
    "$$\n",
    "\n",
    "Here, we see that the internally studentized residual for a given data point depends not only on the ordinary residual, but also the size of the mean square error (MSE) and the leverage $h_{ii}$.\n",
    "\n",
    "As a result, studentized residuals quantify how large the residuals are in standard deviation units, and therefore can be easily used to identify outliers:\n",
    "\n",
    " - An observation with an internally studentized residual that is larger than 3 (in absolute value) is generally deemed an outlier. Sometimes, the term \"outlier\" is reserved for an observation with an *externally* studentized residual that is larger than 3 in absolute value (we'll consider externally studentized residuals in the next section).\n",
    "\n",
    "To see the outliers in the leverage data we imported, we can again use the influence instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20]),)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.abs(infl.resid_studentized_internal) > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why should we care about outliers?\n",
    "The easiest way to understand the impact of outliers is to analyze a data set twice — once with and once without the outlier—and to observe differences in the results.\n",
    "\n",
    "If we regress $y$ on $x$ using the data set without the outlier, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   652.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.35e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:53</td>     <th>  Log-Likelihood:    </th> <td> -46.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   96.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   98.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.7322</td> <td>    1.121</td> <td>    1.546</td> <td> 0.140</td> <td>   -0.622</td> <td>    4.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>     <td>    5.1169</td> <td>    0.200</td> <td>   25.551</td> <td> 0.000</td> <td>    4.696</td> <td>    5.538</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.394</td> <th>  Durbin-Watson:     </th> <td>   2.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.821</td> <th>  Jarque-Bera (JB):  </th> <td>   0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.259</td> <th>  Prob(JB):          </th> <td>   0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.723</td> <th>  Cond. No.          </th> <td>    11.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.973\n",
       "Model:                            OLS   Adj. R-squared:                  0.972\n",
       "Method:                 Least Squares   F-statistic:                     652.8\n",
       "Date:                Fri, 19 Apr 2019   Prob (F-statistic):           1.35e-15\n",
       "Time:                        15:06:53   Log-Likelihood:                -46.374\n",
       "No. Observations:                  20   AIC:                             96.75\n",
       "Df Residuals:                      18   BIC:                             98.74\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.7322      1.121      1.546      0.140      -0.622       4.086\n",
       "x              5.1169      0.200     25.551      0.000       4.696       5.538\n",
       "==============================================================================\n",
       "Omnibus:                        0.394   Durbin-Watson:                   2.066\n",
       "Prob(Omnibus):                  0.821   Jarque-Bera (JB):                0.287\n",
       "Skew:                           0.259   Prob(JB):                        0.866\n",
       "Kurtosis:                       2.723   Cond. No.                         11.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_outlier = sm.OLS(df['y'].iloc[:-1], \n",
    "                          df[['const', 'x']].iloc[:-1]).fit()\n",
    "model_no_outlier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we regress $y$ on $x$ using the full data set with the outlier, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 19 Apr 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:07:09</td>     <th>  Log-Likelihood:    </th> <td> -80.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    21</td>      <th>  AIC:               </th> <td>   165.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   167.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   13.2969</td> <td>    4.411</td> <td>    3.014</td> <td> 0.007</td> <td>    4.065</td> <td>   22.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>     <td>    2.3333</td> <td>    0.656</td> <td>    3.558</td> <td> 0.002</td> <td>    0.961</td> <td>    3.706</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.455</td> <th>  Durbin-Watson:     </th> <td>   0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.005</td> <th>  Jarque-Bera (JB):  </th> <td>   8.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.158</td> <th>  Prob(JB):          </th> <td>  0.0154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.044</td> <th>  Cond. No.          </th> <td>    11.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.400\n",
       "Model:                            OLS   Adj. R-squared:                  0.368\n",
       "Method:                 Least Squares   F-statistic:                     12.66\n",
       "Date:                Fri, 19 Apr 2019   Prob (F-statistic):            0.00210\n",
       "Time:                        15:07:09   Log-Likelihood:                -80.895\n",
       "No. Observations:                  21   AIC:                             165.8\n",
       "Df Residuals:                      19   BIC:                             167.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         13.2969      4.411      3.014      0.007       4.065      22.529\n",
       "x              2.3333      0.656      3.558      0.002       0.961       3.706\n",
       "==============================================================================\n",
       "Omnibus:                       10.455   Durbin-Watson:                   0.898\n",
       "Prob(Omnibus):                  0.005   Jarque-Bera (JB):                8.352\n",
       "Skew:                          -1.158   Prob(JB):                       0.0154\n",
       "Kurtosis:                       5.044   Cond. No.                         11.5\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of the outlier did a few things, but the biggest effect is on the models' mean squared errors (this is the sum of squared residuals divided by the residual degrees of freedom). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.71840030424511"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_outlier.mse_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.527963946104"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_model.mse_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [mean square error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) is substantially inflated from $6.72$ to $143.53$ by the presence of the outlier. Recalling that MSE appears in all of our confidence and prediction interval formulas, the inflated size of MSE would thereby cause a detrimental increase in the width of all of our confidence and prediction intervals.\n",
    "\n",
    "Although including the outlier substantially inflated our coefficent's standard error from $0.107$ to $0.461$ (and the coefficient itself is also quite different), the predicted responses, estimated slope coefficients, and hypothesis test results are not necessarily affected by the inclusion of an outlier. \n",
    "\n",
    "In fact, an outlier can sometimes be so extreme that its influence on the regression model is so great that the estimated regression function is \"pulled\" towards the potential outlier, so that it isn't flagged as an outlier using the standardized residual criterion. To address this issue, **deleted residuals** offer an alternative criterion for identifying outliers. The basic idea is to delete the observations one at a time, each time refitting the regression model on the remaining n–1 observations. Then, we compare the observed response values to their fitted values based on the models with the ith observation deleted. This produces **(unstandardized) deleted residuals**. Standardizing the deleted residuals produces **studentized deleted residuals**, also known as **externally studentized residuals**.\n",
    "\n",
    "#### (Unstandardized) deleted residuals\n",
    "If we let:\n",
    "\n",
    " - $y_i$ denote the observed response for the $i^{th}$ observation, and\n",
    " - $\\hat{y}_{(i)}$ denote the predicted response for the $i^{th}$ observation based on the estimated model with the $i^{th}$ observation deleted\n",
    " \n",
    "then the $i^{th} (unstandardized) deleted residual is defined as:\n",
    "\n",
    "$$\n",
    "d_i=y_i-\\hat{y}_{(i)}\n",
    "$$\n",
    "\n",
    "Data point $i$ being influential implies that the data point \"pulls\" the estimated regression line towards itself. In that case, the observed response would be close to the predicted response. But, if you removed the influential data point from the data set, then the estimated regression line would \"bounce back\" away from the observed response, thereby resulting in a large deleted residual. That is, a data point having a large deleted residual suggests that the data point is influential.\n",
    "\n",
    "In general, **externally studentized residuals are going to be more effective for detecting outlying $Y$ observations than internally studentized residuals.** If an observation has an externally studentized residual that is larger than $3$ (in absolute value) we can call it an outlier.\n",
    "\n",
    "We can access the **externally studentized residuals** with `statsmodels` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20]),)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.abs(infl.get_resid_studentized_external()) > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leverage vs Influence\n",
    "\n",
    "Outliers and high leverage data points have the potential to be influential, but we generally have to investigate further to determine whether or not they are actually influential. That is, does it unduly influence any part of a regression analysis, such as the predicted responses, the estimated slope coefficients, or the hypothesis test results. \n",
    "\n",
    "This is an important distinction because the leverage merely quantifies the potential for a data point to exert strong influence on the regression analysis. The leverage depends only on the predictor values. Whether the data point is **influential** or not also depends on the observed value of the reponse $y_i$.\n",
    "\n",
    "### Influence\n",
    "\n",
    "Here we'll discuss two measures for identifying influential data points:\n",
    "\n",
    " - Difference in fits (DFFITS)\n",
    " - Cook's distance\n",
    " \n",
    "The basic idea behind each of these measures is the same, namely to delete the observations one at a time, each time refitting the regression model on the remaining $n–1$ observations. Then, we compare the results using all $n$ observations to the results with the $i^{th}$ observation deleted to see how much influence the observation has on the analysis. Analyzed as such, we are able to assess the potential impact each data point has on the regression analysis.\n",
    "\n",
    "#### Difference in Fits (DFFITS)\n",
    "The difference in fits for observation i, denoted $DFFITS_i$, is defined as:\n",
    "\n",
    "$$\n",
    "DFFITS_i=\\frac{\\hat{y}_i-\\hat{y}_{(i)}}{\\sqrt{MSE_{(i)}h_{ii}}}\n",
    "$$\n",
    "\n",
    "As you can see, the numerator measures the difference in the predicted responses obtained when the $i_{th}$ data point is included and excluded from the analysis. The denominator is the estimated standard deviation of the difference in the predicted responses. Therefore, the difference in fits quantifies the number of standard deviations that the fitted value changes when the $i_{th}$ data point is omitted.\n",
    "\n",
    "An observation is deemed influential if the absolute value of its DFFITS value is greater than:\n",
    "\n",
    "$$\n",
    "2\\sqrt{\\frac{p+1}{n-p-1}}\n",
    "$$\n",
    "\n",
    "where as always $n$ = the number of observations and $$ = the number of parameters including the intercept.\n",
    "\n",
    "Using this guideline, we can deem a data point as being influential if the absolute value of its DFFITS value is greater than:\n",
    "\n",
    "$$\n",
    "2\\sqrt{\\frac{p+1}{n-p-1}}=2\\sqrt{\\frac{2+1}{21-2-1}}=0.82\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20]),)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.abs(infl.dffits[0]) > .82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we found our outlier that has high leverage to be an influential observation. But what to do with this observation comes down to recognizing that all of these outlier/leverage/influence measures are just tools that *flag* potentially influential data points for the data analyst. In the end, it's up to the analyst to decide if they should analyze the data set twice — once with and once without the flagged data points. If the data points significantly alter the outcome of the regression analysis, then the researcher should report the results of both analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cook's Distance\n",
    "[Cook's distance] is defined as:\n",
    "\n",
    "$$\n",
    "D_i=\\frac{(y_i-\\hat{y}_i)^2}{p \\times MSE}\\left[ \\frac{h_{ii}}{(1-h_{ii})^2}\\right]\n",
    "$$\n",
    "\n",
    "The main thing to recognize is that Cook's $D_i$ depends on both the residual, $e_i$ (in the first term), and the leverage, $h_{ii}$ (in the second term). That is, both the $x$ value and the $y$ value of the data point play a role in the calculation of Cook's distance.\n",
    "\n",
    "In short:\n",
    "\n",
    " - $D_i$ directly summarizes how much all of the fitted values change when the $i^{th}$ observation is deleted.\n",
    " - A data point having a large $D_i$ indicates that the data point strongly influences the fitted values.\n",
    " \n",
    "When we regressed $y$ on $x$ using all $n = 20$ data points, we determined that the estimated intercept coefficient $b_0 = 13.296921$ and the estimated slope coefficient $b_1 = 2.333275$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    13.296921\n",
       "x         2.333275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove the first data point from the data set, and regress $y$ on $x$ using the remaining $n = 19$ data points, the estimated intercept coefficient $b_0$ and estimated slope coefficient $b_1$ should remain about the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    15.396664\n",
       "x         2.083496\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_minus_first = sm.OLS(df['y'].iloc[1:], \n",
    "                           df[['const', 'x']].iloc[1:]).fit()\n",
    "model_minus_first.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would hope and expect, the estimates don't change all that much when removing the one data point. Continuing this process of removing each data point one at a time, and plotting the resulting estimated slopes ($b_1$) versus estimated intercepts ($b_0$), we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12208eda0>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "consts = []\n",
    "slopes = []\n",
    "for i in range(1, df.shape[0]+1):\n",
    "    _df = df.drop([i])\n",
    "    _model = sm.OLS(_df['y'], \n",
    "                    _df[['const', 'x']]).fit()\n",
    "    _params = _model.params\n",
    "    consts.append(_params[0])\n",
    "    slopes.append(_params[1])\n",
    "    \n",
    "plt.scatter(consts, slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the estimated coefficients are *not* all bunched together regardless of which data point is removed. This suggests the presence of an influential observation. Let's see the model's parameters when we remove just the outlier we've identified previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    1.732178\n",
       "x        5.116869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_outlier.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The constant here is estimated to be $1.73$ when it was previously estimated to be $13.296921$. And the slope is not estimated to be $5.12$ when it was previously estimated to be $2.33$. In this case, we would expect the Cook's distance measure, $D_i$, for the outlier to be large and the Cook's distance measures, $D_i$, for the remaining data points to be small. But how big is too big?\n",
    "\n",
    "Here are the guidelines commonly used:\n",
    "\n",
    " - If $D_i$ is greater than $0.5$, then the $i_{th}$ data point is worthy of further investigation as it may be influential.\n",
    " - If $D_i$ is greater than $1$, then the $i_th$ data point is quite likely to be influential.\n",
    " \n",
    "> An alternative method for interpreting Cook's distance that is sometimes used is to relate the measure to the $F(p, n–p)$ distribution and to find the corresponding percentile value. If this percentile is less than about $10$ or $20$ percent, then the case has little apparent influence on the fitted values. On the other hand, if it is near $50$ percent or even higher, then the case has a major influence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Influence\n",
    "We can visually identify influencers with a Residuals vs Leverage plot (also called an influence plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = sm.graphics.influence_plot(lev_model, ax=ax, criterion=\"cooks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what we saw above is confirmed in this plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-data-science",
   "language": "python",
   "name": "learning-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
